{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소규모 데이터셋에서 컨브넷 훈련\n",
    "\n",
    "보통 매우 적은 데이터를 사용해서 이미지 분류 모델을 훈련하는 일은 흔한 경우이다.  \n",
    "'적은' 샘플이란 수백 개에서 수만 개 사이를 의미한다.  \n",
    "예제로 4000개의 강아지와 고양이 사진(강아지 2000개, 고양이 2000개)으로 구성된 데이터셋에서 강아지와 고양이 이미지를 분류해보자.  \n",
    "훈련에 2000개, 검증과 테스트에 각각 1000개의 사진을 사용하도록 하자.  \n",
    "  \n",
    "적은 데이터를 가지고 있을 때, 기본적인 전략 중 하나는 소규모 데이터셋을 사용해서 처음부터 새로운 모델을 훈련하는 것이다.  \n",
    "2000개의 훈련 샘플에서 작은 컨브넷을 어떤 규제 방법도 사용하지 않고 훈련해서 기준이되는 기본성능을 만들어보자.  \n",
    "이 방법은 약 71%의 정확도를 달성할 것인데, 이 방법의 주요 이슈는 과대적합이 될 것이라는 점이다.  \n",
    "그래서 컴퓨터비전에서 과대적합을 줄이기 위한 강력한 방법인 데이터 증식을 사용해서 네트워크의 성능을 82%까지 향상시킬 수 있다.  \n",
    "  \n",
    "다음 절에서는 작은 데이터셋에 딥러닝을 적용하기 위한 핵심적인 두 가지를 살펴보자.  \n",
    "이 방법들은 사전 훈련된 네트워크로 특성을 추출하는 것(90%~96%)과 사전 훈련된 네트워크를 세밀하게 튜닝하는 것이다.  \n",
    "이 세가지 전략(처음부터 작은 모델 훈련, 사전 훈련된 모델을 사용해서 특성 추출, 사전 훈련된 모델을 세밀하게 튜닝하기)는 작은 데이터셋에서 이미지 분류문제를 수행할 때 도구 중에 하나로 사용할 수 있어야 한다.  \n",
    "  \n",
    "# 작은 데이터셋 문제에서 딥러닝의 타당성\n",
    "\n",
    "딥러닝은 데이터가 풍부할 때만 작동한다는 말을 이따금 듣는데, 이는 부분적으로는 맞다.  \n",
    "딥러닝의 근본적인 특징은 훈련 데이터에서 특성공학의 수작업 없이 흥미로운 특성을 찾을 수 있는 것이다.  \n",
    "이는 훈련 샘플이 많아야만 가능하다. 특히 입력 샘플이 이미지같이 고차원인 문제에서는 특히 그렇다.  \n",
    "  \n",
    "많은 샘플이 의미하는 것은 상대적이다.  \n",
    "우선 훈련하려는 네트워크의 크기와 깊이에 상대적이다. 복잡한 문제를 푸는 컨브넷을 수십개의 샘플만을 사용해서 훈련하는 것은 불가능하다.  \n",
    "하지만 모델이 작고 규제가 잘 되어 있고 간단한 작업이라면 수백개의 샘플로도 충분하다. 컨브넷은 지역적이고 평행이동으로 변하지 않는 특성을 학습하기 때문에 지각에 관한 문제에서 데이터를 효율적으로 사용할 수 있다.  \n",
    "매우 작은 이미지 데이터셋에서 어떤 종류의 특성 공학을 사용하지 않고 컨브넷을 처음부터 훈련해도 납득할 만한 결과를 만들 수 있다.  \n",
    "  \n",
    "딥러닝 모델은 태생적으로 다목적이다. 대규모 데이터셋에서 훈련시킨 이미지 분류모델이나 스피치-투-텍스트 모델을 변경해서 다른문제에 재사용할 수도 있다. 특히 컴퓨터 비전에서는(보통 ImageNet 데이터셋에서 훈련된) 사전 훈련된 모델들이 다운로드 받을 수 있도록 많이 공개되어 있어서 매우 적은 데이터에서도 강력한 비전 보델을 만드는데 사용할 수 있다. 다음절에서 직접 해보자..\n",
    "  \n",
    "  \n",
    "# 데이터 내려받기\n",
    "여기서 사용할 강아지, 고양이 데이터셋은 케라스에 포함되어있지 않아서 '캐글'이라는 곳에서 다운받아야 한다.  \n",
    "원본 데이터셋을 https://www.kaggle.com/c/dogs-vs-cats/data 에서 개, 고양이 데이터 셋을 다운 받자.  \n",
    "이 데이터셋은 2013년 후반 캐들에서 컴퓨터 비전 경연대회의 일환으로 이 데이터셋을 만들었다.(2013년도에는 컨브넷을 사용한 참가자가 우승했다고 한다.. 성능은 95%정도 였다고 함)    \n",
    "\n",
    "여기서는 참가자들이 사용했던 데이터의 10%보다 적은 양으로 모델을 훈련하고도 근접한 정확도를 달성해보자.  \n",
    "이 데이터셋은 25000개의 강아지와 고양이 이미지(클래스마다 12500개)를 담고 있고 (압축해서)543MB 크기이다.  \n",
    "다운로드하고 압축을 해제한 후 세개의 서브셋이 들어 있는 새로운 데이터셋을 만들 것이다.  \n",
    "데이터 셋은 클래스마다 1000개의 샘플로 이루어진 훈련세트, 클래스마다 500개의 샘플로 이루어진 검증세트, 클래스마다 500개의 샘플로 이루어진 테스트 세트로 나누도록 하자.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
