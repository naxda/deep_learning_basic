{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2. Training Convnet from scratch on a small dataset\n",
    "\n",
    " - 아주 작은 데이터 모델을 가지고 훈련시키는 것이 일반적이다. 샘플은 수백개에서 수만개의 이미지가 될 수 있고 여기서는 2000장의 그림을 이용할 것임.\n",
    " - 개와 고양이를 분류하기 위해 4000장의 사진을 포함한 데이터세트를 이용하는데 훈련하는데 2000장의 그림을 이용하고 검증을 위해 1000개, 테스트를 이용해서 1000개를 사용할 것임.\n",
    "\n",
    " - 2000개의 데이터세트를 이용해서 훈련을 시키면 분류정확도가 71%가까이되고 **overfitting을 완화하기 위한 방법으로 data augmentation**이라는 것이 있는데, data augementation을 통해서 정확도를 82%까지 높일 수 있다.\n",
    "\n",
    " - 훈련된 데이터세트를 **'feature extraction with a pretrained network'**(pretrained network를 통한 특징추출, 90~96%까지),\n",
    " - **'fine-tuning a pretrained network'(pretrained network tunning, 97%까지)**을 통해서 정확도를 높일 수 있다.(이에 대한 내용은 5.3절을 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.1. The relevance of deep learning for small-data problems\n",
    "(딥러닝에서 작은 데이터셋이 가지는 문제들에 대한 내용)\n",
    "- 딥러닝은 많은 양의 데이터를 사용할 수 있는 경우에만 동작한다고 하지만 이것은 부분적으로 유효하다.  \n",
    "- 딥러닝의 한 가지 기본 특성은 수동 피쳐 엔지니어링을 필요로하지 않고 자체적으로 교육 데이터의 흥미로운 기능을 찾을 수 있다는 것인데, 이는 많은 교육 예제를 사용할 수있을 때만 가능하다.\n",
    "\n",
    "- 그러나 많은 샘플을 구성하는 것은 상대적으로 당신이 훈련하려고하는 **네트워크의 크기와 깊이에 상대적**입니다.  \n",
    "- 단지 수십 개의 샘플만으로 복잡한 문제를 해결할 수는 없지만 **모델이 작고 규칙적이며 작업이 간단하다면 몇백개만으로도 충분하다.** \n",
    "- **아주 작은 이미지 데이터 세트에서 처음부터 convnet을 교육하면** 사용자 정의 기능 엔지니어링 없이도 **데이터가 상대적으로 부족하더라도** 여전히 **합리적인 결과를 얻을 수 있다**.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.2. Downloading the data\n",
    "www.kaggle.com/c/dogs-vs-cats/data(이곳에서 받을 수 있음)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.3. Building your network\n",
    "\n",
    " - convnet은 Conv2D(relu활성화를 이용한), MaxPooling2D 스택을 번갈아 쌓아서 구성하고\n",
    " - 이 예제에서는 많은 이미지들과 더 복잡한 문제들을 다루고 있기 때문에, 네트워크를 다음과 같이 만들것이다( one more + stage ) \n",
    " (But because you're dealing with bigger images and a more complex problem, you'll make your network larger, accordingly: it will have one more + stage.)\n",
    " - 하나의 레이어를 더 붙인다고 하는데, 이 기능은 네트워크의 용량을 늘리고 기능 맵의 크기를 줄이기 위해 제공되므로 Flatten레이어에 도달 할 때 지나치게 커지지 않는다. (아래 구문을 마지막에 한번 더 수행하는 것을 말하는 것으로 보인다.)\n",
    "~~~python\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "~~~\n",
    " \n",
    " - 단일 유닛 (Dense크기 1 의 레이어)과 sigmoid활성화로 네트워크를 종료하게 된다.  \n",
    "\n",
    " #### [TODO] Conv2D함수와 MaxPooling2D의 전달인자를 다시 한번 정리해보자\n",
    "\n",
    " - Conv2D의 첫번째 인자(32, 64, 128, 128,), 두번째 인자는 계속(3,3)이고 세번째인자는 activation='relu'를 넘기고 있다. \n",
    " - 네번째 인자는 처음에만 150x150x3크기를 넘기고 있다.\n",
    " \n",
    " - MaxPooling2D함수의 인자는 계속 (2,2)를 넘기고 있다.  \n",
    " \n",
    " - Dense()함수는 처음에는 512, 와 함께 relu를 활성화시키고, 그 다음은 1과 함께 sigmoid를 넘기고 있는데 이에 대한 의미를 정리하는 것이 필요...  \n",
    "  \n",
    "#### 네트워크 구성  \n",
    "~~~python\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "~~~\n",
    "\n",
    "#### 구성된 네트워크 확인\n",
    "~~~\n",
    ">>> model.summary()\n",
    "Layer (type)                     Output Shape          Param #\n",
    "================================================================\n",
    "conv2d_1 (Conv2D)                (None, 148, 148, 32)  896\n",
    "________________________________________________________________\n",
    "maxpooling2d_1 (MaxPooling2D)    (None, 74, 74, 32)    0\n",
    "________________________________________________________________\n",
    "conv2d_2 (Conv2D)                (None, 72, 72, 64)    18496\n",
    "________________________________________________________________\n",
    "maxpooling2d_2 (MaxPooling2D)    (None, 36, 36, 64)    0\n",
    "________________________________________________________________\n",
    "conv2d_3 (Conv2D)                (None, 34, 34, 128)   73856\n",
    "________________________________________________________________\n",
    "maxpooling2d_3 (MaxPooling2D)    (None, 17, 17, 128)   0\n",
    "________________________________________________________________\n",
    "conv2d_4 (Conv2D)                (None, 15, 15, 128)   147584\n",
    "________________________________________________________________\n",
    "maxpooling2d_4 (MaxPooling2D)    (None, 7, 7, 128)     0\n",
    "________________________________________________________________\n",
    "flatten_1 (Flatten)              (None, 6272)          0\n",
    "________________________________________________________________\n",
    "dense_1 (Dense)                  (None, 512)           3211776\n",
    "________________________________________________________________\n",
    "dense_2 (Dense)                  (None, 1)             513\n",
    "================================================================\n",
    "Total params: 3,453,121\n",
    "Trainable params: 3,453,121\n",
    "Non-trainable params: 0\n",
    "~~~\n",
    "\n",
    "  \n",
    "  \n",
    "- 컴파일 단계에서는 보통 때와 마찬가지로 RMSprop 옵티 마이저를 사용한다. \n",
    "- 하나의 시그모이드 유닛으로 네트워크를 종료했기 때문에 바이너리 크로스 트로피를 손실로 사용하게됩니다  \n",
    "#### 교육을위한 모델 구성\n",
    "~~~python\n",
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "~~~  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.4. Data preprocessing(데이터 전처리)\n",
    "\n",
    "- 이미지를 분류하기 위해서는 지금까지 구성한 네트워크에 데이터를 공급해야하는데, 네트워크에 공급되기 전에 적절하게 처리된 부동소수점 텐서로 형식화되어야 한다.\n",
    "- 이를 위해서는 현재 우리는 jpeg데이터를 사용하므로 다음과 같은 단계를 거쳐야 한다.\n",
    "\n",
    "~~~\n",
    "- 그림 파일 읽기\n",
    "- JPEG을 RGB픽셀로 디코딩\n",
    "- 이것을 부동 소수점 텐서로 변환\n",
    "- 픽셀 값 (0에서 255 사이)을 [0, 1] 간격으로 조정 (신경망은 작은 입력 값을 처리하는 것을 선호하기 때문에 0~255를 0~1사이로 스케일링한다고 함)\n",
    "~~~\n",
    "\n",
    "- Keras에는 이러한 단계를 자동으로 처리하는 이미지 처리 도우미 도구가있는 모듈이 있습니다\n",
    "- keras.preprocessing.image클래스는 ImageDataGenerator클래스를 포함하고있어 디스크의 이미지 파일을 전처리 된 텐서의 일괄 처리로 자동 변환할 수있는 Python 생성기를 빠르게 설정할 수 있습니다.\n",
    "\n",
    "**ImageDataGenerator를 사용하여 디렉토리에서 이미지 읽기**\n",
    "~~~python\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150)\n",
    "        batch_size=20,\n",
    "        class_mode='binary')  \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "~~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
