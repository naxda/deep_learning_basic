{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝의 기본 요소\n",
    "\n",
    "## 머신러닝의 분류\n",
    "책에서는 지도, 비지도, 자기지도, 강화학습의 네가지 분류로 나뉘었지만, 검색해보니 분류법에 따라 약간 차이가 있는 듯하다.\n",
    "nvidia 블로그에 포스팅된 내용으로 이해해보자.  \n",
    "https://blogs.nvidia.co.kr/2018/09/03/supervised-unsupervised-learning/\n",
    "\n",
    "- 지도학습  \n",
    "앞에서 봤던 이진분류, 다중분류, 스칼라회귀도 지도학습의 일종이며, 사람이 레이블링한 데이터 셋이 주어진 상태에서 값을 예측하는 방법이다.\n",
    "아래의 비유가 이해하기에 좋은 표현인듯 하다.  \n",
    "\"만약 여러분이 누군가의 지도 하에 일을 배우고 있다면, 여러분이 올바른 답을 찾는지는 지도하는 사람이 알려줍니다.\"  \n",
    "  \n",
    "즉, 지도학습은 주어진 기존의 라벨링된 데이터셋을 모델이 학습하고, 새로운 데이터에 대해 올바른 분류/예측을 하는 것을 말한다.\n",
    "![supervised learning](img/supervised_learning_block_diagram.png)\n",
    "  \n",
    "- 비지도학습  \n",
    "레이블링되지 않은 데이터를 학습하는 방법이다.  \n",
    "데이터의 구조나 패턴을 파악하는데 주로 사용되며 그 사용예로는 비슷한 특성끼리 묶어주는 클러스터링 알고리즘 이라는 것이 있다.  \n",
    "\n",
    "\n",
    "- 자기지도학습(자율학습)  \n",
    "완벽하게 분류된 깔끔한 데이터 세트는 구하기 쉽지 않고 때때로 연구원들은 자기들도 답을 모르는 문제를 알고리즘에 묻기도 한다. 여기가 바로 자율 학습이 시작된 부분이다.  \n",
    "신경망이 유용한 특징을 추출하고 구조를 분석함으로써 자동적으로 데이터 안에서 구조를 찾으려고 노력한다.\n",
    "이때, 데이터안에서 구조를 찾는 방법은 아래와 같다.\n",
    "![self learning_samples](img/self_learning_samples.png)\n",
    "\n",
    "        군집화(Clustering)  \n",
    "        조류학 전문가가 아니더라도, 새 사진 모음을 보고 깃털 색깔이나 크기, 부리 모양 같은 단서를 통해 대강 종을 구분하는 것은 할 수 있습니다. 이것이 바로 자율 학습을 위한 가장 흔한 적용인 군집화가 이루어지는 방식입니다. 딥러닝 모델은 서로 비슷해 보이는 학습 데이터를 찾아 그룹으로 만듭니다.  \n",
    "\n",
    "        이상 탐지(Anomaly detection)  \n",
    "        은행은 고객의 구매 행동에서 특이한 패턴을 발견함으로써 사기거래를 탐지합니다. 예를 들어, 한 신용카드가 각각 미국 캘리포니아와 덴마크에서 같은 날 사용됐다면, 그건 의혹의 원인이 됩니다. 이와 유사하게, 자율 학습은 데이터 세트에 특정 값을 표시하는데 쓰일 수 있습니다.  \n",
    "\n",
    "        연상(Association)  \n",
    "        온라인 쇼핑 카트에 기저귀, 사과 소스, 빨대 컵을 넣으면 사이트가 저절로 턱받이와 베이비 모니터를 추천해줄 겁니다. 이건 연상의 예시인데요, 바로 데이터 샘플의 어떤 특성을 다른 특성과 연관 짓는 겁니다. 데이터 포인트의 핵심 속성을 두어 개 파악함으로써, 자율 학습 모델은 연관된 다른 속성들을 예측할 수 있습니다.  \n",
    "\n",
    "        오토인코더(Autoencoder)  \n",
    "        오토인코더는 입력 데이터를 가지고 하나의 코드로 압축한 뒤 요약된 코드로부터 입력 데이터를 재생성하려고 합니다. 이건 마치 모비 딕으로 시작해 스파크노트 버전을 생성한 후, 스파크노트만을 참고해 원작을 다시 쓰려고 하는 것과 같습니다. 깔끔한 딥러닝 트릭이긴 하지만, 간단한 오토코더가 실제로 유용한 사례는 별로 없습니다. 하지만 복잡성을 한 층만 더하면 가능성은 불어납니다. 오토인코더는 학습에 한 이미지의 더러운 버전, 깔끔한 버전을 둘 다 씀으로써 이미지, 비디오, 의료용 스캔 같은 시각 데이터에서 노이즈를 제거해 이미지의 품질을 개선시킵니다.  \n",
    " \n",
    "\n",
    "- 반지도학습(지도/자율 학습, semi-supervised learning)  \n",
    "책에서는 지도학습의 한 분류로 반지도학습을 소개하고 있다.  \n",
    "이 방법은 데이터로부터 관련 특성을 도출해내기 어려울 때와 분류된 데이터 예시들이 전문가들에게 시간이 많이 걸리는 작업일 때에 특히 유용하다.  \n",
    "자기지도학습은 스스로 패턴이나 구조를 찾는 방법이지만, 반 지도 학습은 데이터의 작은 한 부분을 통해 분류를 한다고 한다..\n",
    "아직 정확히 이해는 안된다..\n",
    "\n",
    "\n",
    "- 강화학습  \n",
    "인공지능 에이전트는 특정한 목표를 달성하거나 특정한 작업에서의 성능을 개선시키기 위해 최선의 방법을 찾으려고 노력한다.  \n",
    "에이전트가 목표를 향한 행동을 취하면 보상을 받습니다.  \n",
    "전반적인 목표는 가장 큰 최종 보상을 받기 위해 밟아야 하는 최고의 다음 단계를 예측한다.\n",
    "결정을 내리기 위해, 에이전트는 과거 피드백으로부터 배운 것과 더 큰 보상을 가져올 새로운 전략의 탐색에 의존한다. \n",
    "이는 장기적인 전략을 포함하는데, 마치 체스 게임에서 당장 최선의 수가 장기전에서 이기게 해주지는 않듯이, 에이전트는 누적 보상을 극대화하기 위해 노력한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신 러닝 모델 평가\n",
    "### 훈련, 검증, 테스트 세트\n",
    "모델을 평가할 때 보통 훈련, 검증, 테스트 이렇게 3개의 세트로 나눈다.  \n",
    "훈련세트에서 모델을 훈련(학습)하고 검증세트에서 모델을 평가한다.  \n",
    "모델을 출시할 준비가 되면 테스트 세트에서 최종적으로 딱 한번 모델을 테스트한다.  \n",
    "훈련세트와 테스트세트 2개를 사용하지 않고 훈련,검증,테스트 세트로 구성하는 이유는 모델을 개발할 때 (검증세트에서) 항상 모델의 설정을 튜닝하기 때문이다.(검증세트에서 모델의 성능을 평가해서 층의 수나 층의 유닛 수를(하이퍼파라미터) 선택하고 이런 설정들을 튜닝한다.)  \n",
    "\n",
    "### 정보누설\n",
    "검증세트의 성능을 기반으로 모델의 설정을 튜닝하면 검증세트로 모델을 직접 훈련하지 않아도 검증세트에 과대적합 될 수 있다.\n",
    "이는 정보누설 때문이다. 검증세트의 모델 성능에 기반해서 모델의 하이퍼파라미터를 조정할 때마다 검증데이터에 관한 정보가 모델로 새는 것이다.\n",
    "하나의 파라미터에 대해 단 한번만 튜닝한다면 아주 작은 정보가 누설되고 이런 검증 세트로는 모델을 평가할 만하다.\n",
    "하지만, 한번 튜닝하고나서 검증세트에 평가한 결과로 다시 모델을 조정하는 것을 반복하면 검증세트에 관한 정보를 모델에 아주 많이 노출하게 된다.\n",
    "검증데이터에 맞추어서 최적화했기 때문에 검증데이터에 의도적으로 잘 수행되는 모델이 만들어진다.\n",
    "\n",
    "### 단순 홀드아웃 검증\n",
    "데이터의 일정량을 테스트 세트로 떼어놓는 것을 단순 홀드아웃 검증이라고 한다.\n",
    "정보누설을 막기 위해서는 테스트 세트를 사용해서 모델을 튜닝해서는 안된다. 그래서 검증세트도 따로 떼어놓는다.\n",
    "\n",
    "### K겹 교차 검증\n",
    "데이터를 동일한 크기를 가진 K개 분할로 나눈다.  \n",
    "각 분할 i에 대해 남은 K-1개의 분할로 모델을 훈련하고 분할 i에서 모델을 평가한다.  \n",
    "최종점수는 이렇게 얻은 K개의 점수를 평균한다.  \n",
    "이 방법은 데이터 분할에 따라 편차가 클때 도움이 된다.  \n",
    "\n",
    "### 셔플링을 이용한 반복 K-겹 교차 검증\n",
    "가용데이터가 적고 가능한 정확하게 모델을 평가하고자 할 경우 사용.\n",
    "이 방법은 K겹 교차 검증을 여러번 적용하되 K개의 분할로 나누기 전에 매번 데이터를 무작위로 섞는다.\n",
    "최종 점수는 모든 K겹 교차 검증을 실행해서 얻은 점수의 평균이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가 방식 선택 시 유의사항\n",
    " - 대표성 있는 데이터\n",
    " - 시간의 방향\n",
    " - 데이터 중복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특성공학\n",
    "\n",
    "최근 딥러닝은 대부분 특성공학이 필요하지 않다.  \n",
    "신경망이 자동으로 원본에서 유용한 특성을 추출할 수 있기 때문이다.  \n",
    "하지만, 심층 신경망을 사용할 때는 특성공학에 대해 신경을 쓰지 않아도 되는 것은 아니다.\n",
    "특성공학을 사용해서 간단한 문제는 해결할 수 있는 경우도 있기 때문이다.\n",
    "\n",
    " - 좋은 특성은 적은 자원을 사용하여 문제를 더 잘 찾아낼 수 있다. 예를 들어 시계 바늘을 읽는 문제에 합성곱 신경망을 사용하는 것은 어울리지 않는다.\n",
    " - 좋은 특성은 더 적은 데이터로 문제를 풀 수 있다. 딥러닝 모델이 스스로 특성을 학습하는 능력은 가용한 훈련데이터가 많을 때 발휘된다. 샘플의 갯수가 적다면 특성에 있는 정보가 매우 중요하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
