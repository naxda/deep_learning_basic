{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소규모 데이터셋에서 컨브넷 훈련\n",
    "### 적은 샘플의 기준?, 데이터셋\n",
    "매우 적은 데이터를 사용해서 이미지 분류 모델을 훈련해야하는 경우가 있는데 여기서 '적은' 샘플이란 수백 개에서 수만 개 사이를 의미한다.  \n",
    "데이터셋이 적은 경우 정확도가 낮춰질 수 있지만, 이런 경우를 위한 방법들이 몇가지 있는데 예제를 통해서 살펴보자.\n",
    "예제에서 사용할 데이터셋은 강아지사진 2000개, 고양이 사진 2000개로 구성되어있다. 훈련에 2000개, 검증에 1000개, 테스트에 1000개의 사진을 사용해보자.\n",
    "  \n",
    "### 적은 데이터셋의 문제 해결전략1(소규모 데이터셋으로 훈련, 데이터 증식)\n",
    "적은 데이터를 가지고 있을 때, 기본적인 전략 중 하나는 소규모 데이터셋을 사용해서 처음부터 새로운 모델을 훈련하는 것인데, 2000개의 훈련 샘플에서 작은 컨브넷을 훈련해서 기준이되는 기본성능을 만들어보자.  \n",
    "이 방법은 약 71%의 정확도를 달성할 것인데, 이 방법의 주요 이슈는 과대적합이 될 것이라는 점이다.  \n",
    "그래서 컴퓨터비전에서 과대적합을 줄이기 위한 강력한 방법인 데이터 증식을 사용해서 네트워크의 성능을 82%까지 향상시킬 것이다.  \n",
    "  \n",
    "### 적은데이터셋의 문제에 대한 그 외의 해결전략\n",
    "다음 절에서는 작은 데이터셋에 딥러닝을 적용하기 위한 핵심적인 두 가지를 살펴보자.  \n",
    "이 방법들은 사전 훈련된 네트워크로 특성을 추출하는 것(90%~96%)과 사전 훈련된 네트워크를 세밀하게 튜닝하는 것이다.  \n",
    "이 세가지 전략들은 작은 데이터셋에서 이미지 분류문제를 수행할 때 도구 중에 하나로 사용할 수 있어야 한다.  \n",
    " - 처음부터 작은 모델 훈련\n",
    " - 사전 훈련된 모델을 사용해서 특성 추출\n",
    " - 사전 훈련된 모델을 세밀하게 튜닝\n",
    "  \n",
    "# 작은 데이터셋 문제에서 딥러닝의 타당성\n",
    "### 딥러닝은 데이터가 풍부해야만 된다?\n",
    "딥러닝은 데이터가 풍부할 때만 작동한다는 말을 이따금 듣는데, 이는 부분적으로는 맞다.  \n",
    "딥러닝의 기본적인 특징은 훈련 데이터에서 특성공학의 수작업 없이 특성을 찾을 수 있는 것인데, 이는 훈련 샘플이 많아야만 가능하기 때문이다.  \n",
    "특히 입력 샘플이 이미지같이 고차원인 문제에서는 특히 그렇다.  \n",
    "  \n",
    "### 작은 데이터 셋에서도 컨브넷이 좋은 결과를 이끌어낼 수 있는 이유?(지역패턴, 평행이동)\n",
    "그렇지만 많은 샘플이 의미하는 것은 상대적이다.  \n",
    "우선 훈련하려는 네트워크의 크기와 깊이에 상대적이다. 복잡한 문제를 푸는 컨브넷을 수십개의 샘플만을 사용해서 훈련하는 것은 불가능하다.  \n",
    "하지만 모델이 작고 규제가 잘 되어 있고 간단한 작업이라면 수백개의 샘플로도 충분하다. 컨브넷은 지역적이고 평행이동으로 변하지 않는 특성을 학습하기 때문에 지각에 관한 문제에서 데이터를 효율적으로 사용할 수 있다.  \n",
    "매우 작은 이미지 데이터셋에서 어떤 종류의 특성 공학을 사용하지 않고 컨브넷을 처음부터 훈련해도 납득할만한 결과를 만들 수 있다.  \n",
    "  \n",
    "### 딥러닝 모델의 특성(다목적,,, 이미지를 위해 구성한 모델로 STT모델에서도 활용이 가능하다)\n",
    "딥러닝 모델은 태생적으로 다목적이다. 대규모 데이터셋에서 훈련시킨 이미지 분류모델이나 스피치-투-텍스트 모델을 변경해서 다른문제에 재사용할 수도 있다. 특히 컴퓨터 비전에서는(보통 ImageNet 데이터셋에서 훈련된) 사전 훈련된 모델들이 다운로드 받을 수 있도록 많이 공개되어 있어서 매우 적은 데이터에서도 강력한 비전 보델을 만드는데 사용할 수 있다. 다음절에서 직접 해보자..\n",
    "  \n",
    "  \n",
    "# 데이터 내려받기\n",
    "### 데이터셋 준비, 캐글\n",
    "여기서 사용할 강아지, 고양이 데이터셋은 케라스에 포함되어있지 않아서 '캐글'이라는 곳에서 다운받아야 한다.  \n",
    "원본 데이터셋을 https://www.kaggle.com/c/dogs-vs-cats/data 에서 개, 고양이 데이터 셋을 다운 받자.  \n",
    "이 데이터셋은 2013년 후반 캐글에서 컴퓨터 비전 경연대회의 일환으로 이 데이터셋을 만들었다.(2013년도에는 컨브넷을 사용한 참가자가 우승했다고 한다.. 성능은 95%정도 였다고 함)    \n",
    "\n",
    "### 데이터셋 구성\n",
    "여기서는 참가자들이 사용했던 데이터의 10%보다 적은 양으로 모델을 훈련하고도 근접한 정확도를 달성해보자.  \n",
    "이 데이터셋은 총 25000개, 강아지 12500개, 고양이 12500개를 담고 있고 (압축해서)543MB 크기이고, 압축을 해제한 후 세개의 서브셋이 들어 있는 새로운 데이터셋을 만들 것이다.  \n",
    "데이터셋은 클래스마다 1000개의 샘플로 이루어진 훈련세트, 클래스마다 500개의 샘플로 이루어진 검증세트, 클래스마다 500개의 샘플로 이루어진 테스트 세트로 나누도록 하자.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
