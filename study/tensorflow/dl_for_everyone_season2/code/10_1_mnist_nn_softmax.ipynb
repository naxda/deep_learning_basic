{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10_1_mnist_nn_softmax.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Bngi9BpVCwCT","colab_type":"code","outputId":"3de18739-ebf8-408d-eb4a-e338b73a5b76","executionInfo":{"status":"ok","timestamp":1558263831611,"user_tz":-540,"elapsed":35795,"user":{"displayName":"SoonYoung Jung","photoUrl":"","userId":"08526165032976493552"}},"colab":{"base_uri":"https://localhost:8080/","height":8695}},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.datasets import mnist\n","from time import time\n","import os\n","\n","tf.enable_eager_execution()\n","\n","def load(model, checkpoint_dir):\n","    print(\" [*] Reading checkpoints...\")\n","    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n","    if ckpt :\n","        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n","        checkpoint = tf.train.Checkpoint(dnn=model)\n","        checkpoint.restore(save_path=os.path.join(checkpoint_dir, ckpt_name))\n","        counter = int(ckpt_name.split('-')[1])\n","        print(\" [*] Success to read {}\".format(ckpt_name))\n","        return True, counter\n","    else:\n","        print(\" [*] Failed to find a checkpoint\")\n","        return False, 0\n","\n","def check_folder(dir):\n","    if not os.path.exists(dir):\n","        os.makedirs(dir)\n","    return dir\n","\n","\n","# Data load & pre-processing function\n","def load_mnist() :\n","    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n","    train_data = np.expand_dims(train_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n","    test_data = np.expand_dims(test_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n","\n","    train_data, test_data = normalize(train_data, test_data)\n","\n","    train_labels = to_categorical(train_labels, 10) # [N,] -> [N, 10]\n","    test_labels = to_categorical(test_labels, 10) # [N,] -> [N, 10]\n","\n","    return train_data, train_labels, test_data, test_labels\n","\n","def normalize(train_data, test_data):\n","    train_data = train_data.astype(np.float32) / 255.0\n","    test_data = test_data.astype(np.float32) / 255.0\n","\n","    return train_data, test_data\n","\n","# Performance function\n","def loss_fn(model, images, labels):\n","    logits = model(images, training=True)\n","    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n","    return loss\n","\n","def accuracy_fn(model, images, labels):\n","    logits = model(images, training=False)\n","    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n","    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n","    return accuracy\n","\n","def grad(model, images, labels):\n","    with tf.GradientTape() as tape:\n","        loss = loss_fn(model, images, labels)\n","    return tape.gradient(loss, model.variables)\n","\n","# Model function\n","def flatten() :\n","    return tf.keras.layers.Flatten()\n","\n","def dense(label_dim, weight_init) :\n","    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n","\n","def sigmoid() :\n","    return tf.keras.layers.Activation(tf.keras.activations.sigmoid)\n","\n","# Create model (class version)\n","class create_model_class(tf.keras.Model):\n","    def __init__(self, label_dim):\n","        super(create_model_class, self).__init__()\n","        weight_init = tf.keras.initializers.RandomNormal()\n","\n","        self.model = tf.keras.Sequential()\n","        self.model.add(flatten())\n","\n","        for i in range(2):\n","            self.model.add(dense(256, weight_init))\n","            self.model.add(sigmoid())\n","\n","        self.model.add(dense(label_dim, weight_init))\n","\n","    def call(self, x, training=None, mask=None):\n","        x = self.model(x)\n","\n","        return x\n","\n","# Create model (function version)\n","def create_model_function(label_dim) :\n","    weight_init = tf.keras.initializers.RandomNormal()\n","\n","    model = tf.keras.Sequential()\n","    model.add(flatten())\n","\n","    for i in range(2) :\n","        model.add(dense(256, weight_init))\n","        model.add(sigmoid())\n","\n","    model.add(dense(label_dim, weight_init))\n","\n","    return model\n","\n","# Define data & hyper-parameter\n","\"\"\" dataset \"\"\"\n","train_x, train_y, test_x, test_y = load_mnist()\n","\n","\"\"\" parameters \"\"\"\n","learning_rate = 0.001\n","batch_size = 128\n","\n","training_epochs = 1\n","training_iterations = len(train_x) // batch_size\n","\n","label_dim = 10\n","\n","train_flag = True\n","\n","\"\"\" Graph Input using Dataset API \"\"\"\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n","    shuffle(buffer_size=100000).\\\n","    prefetch(buffer_size=batch_size).\\\n","    batch(batch_size).\\\n","    repeat()\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n","    shuffle(buffer_size=100000).\\\n","    prefetch(buffer_size=len(test_x)).\\\n","    batch(len(test_x)).\\\n","    repeat()\n","\n","train_iterator = train_dataset.make_one_shot_iterator()\n","test_iterator = test_dataset.make_one_shot_iterator()\n","\n","# Define model & optimizer & writer\n","\n","\n","\"\"\" Model \"\"\" \n","network = create_model_function(label_dim)\n","\n","\"\"\" Training \"\"\"\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","\n","\"\"\" Writer \"\"\"\n","checkpoint_dir = 'checkpoints'\n","logs_dir = 'logs'\n","\n","model_dir = 'nn_softmax'\n","\n","checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n","check_folder(checkpoint_dir)\n","checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n","logs_dir = os.path.join(logs_dir, model_dir)\n","\n","\n","# Restore checkpoint & start train or test phase\n","if train_flag :\n","\n","    checkpoint = tf.train.Checkpoint(dnn=network)\n","\n","    # create writer for tensorboard\n","    summary_writer = tf.contrib.summary.create_file_writer(logdir=logs_dir)\n","    start_time = time()\n","\n","    # restore check-point if it exits\n","    could_load, checkpoint_counter = load(network, checkpoint_dir)\n","    global_step = tf.train.create_global_step()\n","\n","    if could_load:\n","        start_epoch = (int)(checkpoint_counter / training_iterations)\n","        start_iteration = checkpoint_counter - start_epoch * training_iterations\n","        counter = checkpoint_counter\n","        global_step.assign(checkpoint_counter)\n","        print(\" [*] Load SUCCESS\")\n","    else:\n","        start_epoch = 0\n","        start_iteration = 0\n","        counter = 0\n","        print(\" [!] Load failed...\")\n","    \n","    # train phase\n","    with summary_writer.as_default(), tf.contrib.summary.always_record_summaries():  # for tensorboard\n","        for epoch in range(start_epoch, training_epochs):\n","            for idx in range(start_iteration, training_iterations):\n","                train_input, train_label = train_iterator.get_next()\n","                grads = grad(network, train_input, train_label)\n","                optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables), global_step=global_step)\n","\n","                train_loss = loss_fn(network, train_input, train_label)\n","                train_accuracy = accuracy_fn(network, train_input, train_label)\n","\n","                test_input, test_label = test_iterator.get_next()\n","                test_accuracy = accuracy_fn(network, test_input, test_label)\n","\n","                tf.contrib.summary.scalar(name='train_loss', tensor=train_loss)\n","                tf.contrib.summary.scalar(name='train_accuracy', tensor=train_accuracy)\n","                tf.contrib.summary.scalar(name='test_accuracy', tensor=test_accuracy)\n","\n","                print(\n","                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n","                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n","                       test_accuracy))\n","                counter += 1\n","        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n","        \n","# test phase      \n","else :\n","    _, _ = load(network, checkpoint_dir)\n","    test_input, test_label = test_iterator.get_next()\n","    test_accuracy = accuracy_fn(network, test_input, test_label)\n","\n","    print(\"test_Accuracy: %.4f\" % (test_accuracy))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n"," [*] Reading checkpoints...\n"," [*] Failed to find a checkpoint\n"," [!] Load failed...\n","Epoch: [ 0] [    0/  468] time: 0.6124, train_loss: 2.27427626, train_accuracy: 0.1406, test_Accuracy: 0.0974\n","Epoch: [ 0] [    1/  468] time: 0.6928, train_loss: 2.28967834, train_accuracy: 0.1250, test_Accuracy: 0.1093\n","Epoch: [ 0] [    2/  468] time: 0.7646, train_loss: 2.26905799, train_accuracy: 0.1328, test_Accuracy: 0.1032\n","Epoch: [ 0] [    3/  468] time: 0.8368, train_loss: 2.31377816, train_accuracy: 0.0938, test_Accuracy: 0.1032\n","Epoch: [ 0] [    4/  468] time: 0.9057, train_loss: 2.30215645, train_accuracy: 0.1016, test_Accuracy: 0.1048\n","Epoch: [ 0] [    5/  468] time: 0.9732, train_loss: 2.26887417, train_accuracy: 0.1562, test_Accuracy: 0.1495\n","Epoch: [ 0] [    6/  468] time: 1.0440, train_loss: 2.22177005, train_accuracy: 0.1797, test_Accuracy: 0.1296\n","Epoch: [ 0] [    7/  468] time: 1.1155, train_loss: 2.24898505, train_accuracy: 0.1797, test_Accuracy: 0.1779\n","Epoch: [ 0] [    8/  468] time: 1.1846, train_loss: 2.19855785, train_accuracy: 0.3047, test_Accuracy: 0.2146\n","Epoch: [ 0] [    9/  468] time: 1.2550, train_loss: 2.27912760, train_accuracy: 0.1953, test_Accuracy: 0.2547\n","Epoch: [ 0] [   10/  468] time: 1.3231, train_loss: 2.21615124, train_accuracy: 0.2734, test_Accuracy: 0.2771\n","Epoch: [ 0] [   11/  468] time: 1.3911, train_loss: 2.21973944, train_accuracy: 0.3516, test_Accuracy: 0.3776\n","Epoch: [ 0] [   12/  468] time: 1.4649, train_loss: 2.17302942, train_accuracy: 0.6406, test_Accuracy: 0.5648\n","Epoch: [ 0] [   13/  468] time: 1.5455, train_loss: 2.18239570, train_accuracy: 0.5078, test_Accuracy: 0.4820\n","Epoch: [ 0] [   14/  468] time: 1.6144, train_loss: 2.21488428, train_accuracy: 0.4688, test_Accuracy: 0.4883\n","Epoch: [ 0] [   15/  468] time: 1.6865, train_loss: 2.15239954, train_accuracy: 0.4844, test_Accuracy: 0.4431\n","Epoch: [ 0] [   16/  468] time: 1.7546, train_loss: 2.16129184, train_accuracy: 0.3203, test_Accuracy: 0.2590\n","Epoch: [ 0] [   17/  468] time: 1.8220, train_loss: 2.14412928, train_accuracy: 0.2656, test_Accuracy: 0.2162\n","Epoch: [ 0] [   18/  468] time: 1.8935, train_loss: 2.15725803, train_accuracy: 0.1875, test_Accuracy: 0.2256\n","Epoch: [ 0] [   19/  468] time: 1.9626, train_loss: 2.14189339, train_accuracy: 0.2344, test_Accuracy: 0.2947\n","Epoch: [ 0] [   20/  468] time: 2.0315, train_loss: 2.04493451, train_accuracy: 0.5469, test_Accuracy: 0.4395\n","Epoch: [ 0] [   21/  468] time: 2.1047, train_loss: 2.06093645, train_accuracy: 0.5000, test_Accuracy: 0.4487\n","Epoch: [ 0] [   22/  468] time: 2.1756, train_loss: 2.05306244, train_accuracy: 0.3828, test_Accuracy: 0.3948\n","Epoch: [ 0] [   23/  468] time: 2.2439, train_loss: 2.07523108, train_accuracy: 0.3984, test_Accuracy: 0.3959\n","Epoch: [ 0] [   24/  468] time: 2.3135, train_loss: 2.04720092, train_accuracy: 0.4219, test_Accuracy: 0.4235\n","Epoch: [ 0] [   25/  468] time: 2.3827, train_loss: 1.95036054, train_accuracy: 0.5156, test_Accuracy: 0.4499\n","Epoch: [ 0] [   26/  468] time: 2.4506, train_loss: 2.04272723, train_accuracy: 0.3750, test_Accuracy: 0.4266\n","Epoch: [ 0] [   27/  468] time: 2.5327, train_loss: 2.00080085, train_accuracy: 0.3672, test_Accuracy: 0.4109\n","Epoch: [ 0] [   28/  468] time: 2.6040, train_loss: 1.95651603, train_accuracy: 0.3984, test_Accuracy: 0.4106\n","Epoch: [ 0] [   29/  468] time: 2.6728, train_loss: 1.94514227, train_accuracy: 0.4297, test_Accuracy: 0.4328\n","Epoch: [ 0] [   30/  468] time: 2.7419, train_loss: 1.95414424, train_accuracy: 0.4062, test_Accuracy: 0.4682\n","Epoch: [ 0] [   31/  468] time: 2.8105, train_loss: 1.87487507, train_accuracy: 0.5703, test_Accuracy: 0.5405\n","Epoch: [ 0] [   32/  468] time: 2.8786, train_loss: 1.85762048, train_accuracy: 0.6094, test_Accuracy: 0.5989\n","Epoch: [ 0] [   33/  468] time: 2.9487, train_loss: 1.82402110, train_accuracy: 0.6406, test_Accuracy: 0.6127\n","Epoch: [ 0] [   34/  468] time: 3.0167, train_loss: 1.82673788, train_accuracy: 0.6016, test_Accuracy: 0.5888\n","Epoch: [ 0] [   35/  468] time: 3.0856, train_loss: 1.76639557, train_accuracy: 0.6484, test_Accuracy: 0.5628\n","Epoch: [ 0] [   36/  468] time: 3.1561, train_loss: 1.74390936, train_accuracy: 0.5781, test_Accuracy: 0.5277\n","Epoch: [ 0] [   37/  468] time: 3.2253, train_loss: 1.75929642, train_accuracy: 0.4531, test_Accuracy: 0.4987\n","Epoch: [ 0] [   38/  468] time: 3.2932, train_loss: 1.73307836, train_accuracy: 0.4219, test_Accuracy: 0.4899\n","Epoch: [ 0] [   39/  468] time: 3.3643, train_loss: 1.74301767, train_accuracy: 0.5469, test_Accuracy: 0.5248\n","Epoch: [ 0] [   40/  468] time: 3.4327, train_loss: 1.76531529, train_accuracy: 0.4688, test_Accuracy: 0.5473\n","Epoch: [ 0] [   41/  468] time: 3.4990, train_loss: 1.67566216, train_accuracy: 0.5547, test_Accuracy: 0.5623\n","Epoch: [ 0] [   42/  468] time: 3.5882, train_loss: 1.64158297, train_accuracy: 0.6094, test_Accuracy: 0.5881\n","Epoch: [ 0] [   43/  468] time: 3.6573, train_loss: 1.59068072, train_accuracy: 0.6328, test_Accuracy: 0.6270\n","Epoch: [ 0] [   44/  468] time: 3.7239, train_loss: 1.56284928, train_accuracy: 0.7422, test_Accuracy: 0.6698\n","Epoch: [ 0] [   45/  468] time: 3.7923, train_loss: 1.59731829, train_accuracy: 0.6484, test_Accuracy: 0.7055\n","Epoch: [ 0] [   46/  468] time: 3.8617, train_loss: 1.54871440, train_accuracy: 0.7812, test_Accuracy: 0.7146\n","Epoch: [ 0] [   47/  468] time: 3.9293, train_loss: 1.47409511, train_accuracy: 0.7266, test_Accuracy: 0.7062\n","Epoch: [ 0] [   48/  468] time: 3.9969, train_loss: 1.52050161, train_accuracy: 0.6484, test_Accuracy: 0.6977\n","Epoch: [ 0] [   49/  468] time: 4.0673, train_loss: 1.46772754, train_accuracy: 0.6875, test_Accuracy: 0.6980\n","Epoch: [ 0] [   50/  468] time: 4.1396, train_loss: 1.42816949, train_accuracy: 0.7188, test_Accuracy: 0.7008\n","Epoch: [ 0] [   51/  468] time: 4.2110, train_loss: 1.46453357, train_accuracy: 0.6406, test_Accuracy: 0.7008\n","Epoch: [ 0] [   52/  468] time: 4.2789, train_loss: 1.38456345, train_accuracy: 0.6875, test_Accuracy: 0.7030\n","Epoch: [ 0] [   53/  468] time: 4.3461, train_loss: 1.40804398, train_accuracy: 0.6641, test_Accuracy: 0.6937\n","Epoch: [ 0] [   54/  468] time: 4.4128, train_loss: 1.31956279, train_accuracy: 0.7031, test_Accuracy: 0.6810\n","Epoch: [ 0] [   55/  468] time: 4.4836, train_loss: 1.26349032, train_accuracy: 0.6641, test_Accuracy: 0.6616\n","Epoch: [ 0] [   56/  468] time: 4.5528, train_loss: 1.26289320, train_accuracy: 0.6875, test_Accuracy: 0.6396\n","Epoch: [ 0] [   57/  468] time: 4.6433, train_loss: 1.32625961, train_accuracy: 0.6094, test_Accuracy: 0.6327\n","Epoch: [ 0] [   58/  468] time: 4.7118, train_loss: 1.19861257, train_accuracy: 0.7109, test_Accuracy: 0.6319\n","Epoch: [ 0] [   59/  468] time: 4.7779, train_loss: 1.24912071, train_accuracy: 0.6094, test_Accuracy: 0.6422\n","Epoch: [ 0] [   60/  468] time: 4.8431, train_loss: 1.21095479, train_accuracy: 0.7109, test_Accuracy: 0.6617\n","Epoch: [ 0] [   61/  468] time: 4.9145, train_loss: 1.20822811, train_accuracy: 0.6797, test_Accuracy: 0.6807\n","Epoch: [ 0] [   62/  468] time: 4.9814, train_loss: 1.26537859, train_accuracy: 0.6250, test_Accuracy: 0.7030\n","Epoch: [ 0] [   63/  468] time: 5.0476, train_loss: 1.11316097, train_accuracy: 0.7656, test_Accuracy: 0.7291\n","Epoch: [ 0] [   64/  468] time: 5.1151, train_loss: 1.18158770, train_accuracy: 0.6641, test_Accuracy: 0.7478\n","Epoch: [ 0] [   65/  468] time: 5.1858, train_loss: 1.16206145, train_accuracy: 0.7109, test_Accuracy: 0.7613\n","Epoch: [ 0] [   66/  468] time: 5.2529, train_loss: 1.00259805, train_accuracy: 0.8516, test_Accuracy: 0.7629\n","Epoch: [ 0] [   67/  468] time: 5.3221, train_loss: 1.09505904, train_accuracy: 0.7422, test_Accuracy: 0.7614\n","Epoch: [ 0] [   68/  468] time: 5.3896, train_loss: 1.09177244, train_accuracy: 0.6875, test_Accuracy: 0.7618\n","Epoch: [ 0] [   69/  468] time: 5.4549, train_loss: 1.10537624, train_accuracy: 0.7578, test_Accuracy: 0.7616\n","Epoch: [ 0] [   70/  468] time: 5.5200, train_loss: 1.00688887, train_accuracy: 0.8047, test_Accuracy: 0.7589\n","Epoch: [ 0] [   71/  468] time: 5.5908, train_loss: 1.11244941, train_accuracy: 0.7344, test_Accuracy: 0.7535\n","Epoch: [ 0] [   72/  468] time: 5.6721, train_loss: 1.02320290, train_accuracy: 0.7344, test_Accuracy: 0.7507\n","Epoch: [ 0] [   73/  468] time: 5.7386, train_loss: 0.98589110, train_accuracy: 0.7656, test_Accuracy: 0.7508\n","Epoch: [ 0] [   74/  468] time: 5.8062, train_loss: 0.99174881, train_accuracy: 0.7344, test_Accuracy: 0.7540\n","Epoch: [ 0] [   75/  468] time: 5.8715, train_loss: 1.07119286, train_accuracy: 0.7109, test_Accuracy: 0.7625\n","Epoch: [ 0] [   76/  468] time: 5.9360, train_loss: 0.95644850, train_accuracy: 0.7422, test_Accuracy: 0.7724\n","Epoch: [ 0] [   77/  468] time: 6.0001, train_loss: 0.98811471, train_accuracy: 0.7656, test_Accuracy: 0.7844\n","Epoch: [ 0] [   78/  468] time: 6.0698, train_loss: 0.90739781, train_accuracy: 0.8438, test_Accuracy: 0.7957\n","Epoch: [ 0] [   79/  468] time: 6.1370, train_loss: 0.82144642, train_accuracy: 0.8125, test_Accuracy: 0.8033\n","Epoch: [ 0] [   80/  468] time: 6.2015, train_loss: 0.85167980, train_accuracy: 0.8281, test_Accuracy: 0.8027\n","Epoch: [ 0] [   81/  468] time: 6.2656, train_loss: 0.88320267, train_accuracy: 0.8281, test_Accuracy: 0.7995\n","Epoch: [ 0] [   82/  468] time: 6.3388, train_loss: 0.94127268, train_accuracy: 0.7422, test_Accuracy: 0.8008\n","Epoch: [ 0] [   83/  468] time: 6.4049, train_loss: 0.87340713, train_accuracy: 0.7969, test_Accuracy: 0.8008\n","Epoch: [ 0] [   84/  468] time: 6.4704, train_loss: 0.89546227, train_accuracy: 0.7422, test_Accuracy: 0.8041\n","Epoch: [ 0] [   85/  468] time: 6.5350, train_loss: 0.82988799, train_accuracy: 0.8125, test_Accuracy: 0.8113\n","Epoch: [ 0] [   86/  468] time: 6.6068, train_loss: 0.79630899, train_accuracy: 0.8125, test_Accuracy: 0.8138\n","Epoch: [ 0] [   87/  468] time: 6.6840, train_loss: 0.76587254, train_accuracy: 0.8359, test_Accuracy: 0.8154\n","Epoch: [ 0] [   88/  468] time: 6.7528, train_loss: 0.84532410, train_accuracy: 0.7578, test_Accuracy: 0.8172\n","Epoch: [ 0] [   89/  468] time: 6.8344, train_loss: 0.87500644, train_accuracy: 0.7969, test_Accuracy: 0.8143\n","Epoch: [ 0] [   90/  468] time: 6.8996, train_loss: 0.90631866, train_accuracy: 0.7656, test_Accuracy: 0.8113\n","Epoch: [ 0] [   91/  468] time: 6.9642, train_loss: 0.79504871, train_accuracy: 0.8125, test_Accuracy: 0.8071\n","Epoch: [ 0] [   92/  468] time: 7.0276, train_loss: 0.75008953, train_accuracy: 0.8594, test_Accuracy: 0.8082\n","Epoch: [ 0] [   93/  468] time: 7.0964, train_loss: 0.79772449, train_accuracy: 0.8047, test_Accuracy: 0.8114\n","Epoch: [ 0] [   94/  468] time: 7.1640, train_loss: 0.68481684, train_accuracy: 0.8281, test_Accuracy: 0.8121\n","Epoch: [ 0] [   95/  468] time: 7.2290, train_loss: 0.72167820, train_accuracy: 0.8359, test_Accuracy: 0.8135\n","Epoch: [ 0] [   96/  468] time: 7.2933, train_loss: 0.76164007, train_accuracy: 0.8125, test_Accuracy: 0.8154\n","Epoch: [ 0] [   97/  468] time: 7.3635, train_loss: 0.71694744, train_accuracy: 0.8203, test_Accuracy: 0.8203\n","Epoch: [ 0] [   98/  468] time: 7.4291, train_loss: 0.83731985, train_accuracy: 0.7891, test_Accuracy: 0.8237\n","Epoch: [ 0] [   99/  468] time: 7.4934, train_loss: 0.72468466, train_accuracy: 0.8125, test_Accuracy: 0.8287\n","Epoch: [ 0] [  100/  468] time: 7.5578, train_loss: 0.79627001, train_accuracy: 0.8125, test_Accuracy: 0.8352\n","Epoch: [ 0] [  101/  468] time: 7.6278, train_loss: 0.60946018, train_accuracy: 0.8672, test_Accuracy: 0.8419\n","Epoch: [ 0] [  102/  468] time: 7.6973, train_loss: 0.78805602, train_accuracy: 0.8203, test_Accuracy: 0.8477\n","Epoch: [ 0] [  103/  468] time: 7.7702, train_loss: 0.62816399, train_accuracy: 0.8906, test_Accuracy: 0.8519\n","Epoch: [ 0] [  104/  468] time: 7.8369, train_loss: 0.73543829, train_accuracy: 0.8125, test_Accuracy: 0.8525\n","Epoch: [ 0] [  105/  468] time: 7.9010, train_loss: 0.61620986, train_accuracy: 0.8594, test_Accuracy: 0.8513\n","Epoch: [ 0] [  106/  468] time: 7.9639, train_loss: 0.68275905, train_accuracy: 0.8516, test_Accuracy: 0.8501\n","Epoch: [ 0] [  107/  468] time: 8.0300, train_loss: 0.69638395, train_accuracy: 0.8203, test_Accuracy: 0.8484\n","Epoch: [ 0] [  108/  468] time: 8.0979, train_loss: 0.70677292, train_accuracy: 0.8203, test_Accuracy: 0.8450\n","Epoch: [ 0] [  109/  468] time: 8.1633, train_loss: 0.56451666, train_accuracy: 0.8984, test_Accuracy: 0.8445\n","Epoch: [ 0] [  110/  468] time: 8.2271, train_loss: 0.67928004, train_accuracy: 0.8672, test_Accuracy: 0.8437\n","Epoch: [ 0] [  111/  468] time: 8.2902, train_loss: 0.62066215, train_accuracy: 0.8359, test_Accuracy: 0.8463\n","Epoch: [ 0] [  112/  468] time: 8.3612, train_loss: 0.59953582, train_accuracy: 0.8828, test_Accuracy: 0.8494\n","Epoch: [ 0] [  113/  468] time: 8.4284, train_loss: 0.56830764, train_accuracy: 0.8906, test_Accuracy: 0.8551\n","Epoch: [ 0] [  114/  468] time: 8.4908, train_loss: 0.60851407, train_accuracy: 0.8516, test_Accuracy: 0.8583\n","Epoch: [ 0] [  115/  468] time: 8.5534, train_loss: 0.67755896, train_accuracy: 0.8281, test_Accuracy: 0.8599\n","Epoch: [ 0] [  116/  468] time: 8.6224, train_loss: 0.58928758, train_accuracy: 0.8672, test_Accuracy: 0.8603\n","Epoch: [ 0] [  117/  468] time: 8.6869, train_loss: 0.61954969, train_accuracy: 0.8203, test_Accuracy: 0.8613\n","Epoch: [ 0] [  118/  468] time: 8.7577, train_loss: 0.65669060, train_accuracy: 0.8438, test_Accuracy: 0.8622\n","Epoch: [ 0] [  119/  468] time: 8.8263, train_loss: 0.54076040, train_accuracy: 0.8984, test_Accuracy: 0.8613\n","Epoch: [ 0] [  120/  468] time: 8.8926, train_loss: 0.56301725, train_accuracy: 0.8906, test_Accuracy: 0.8623\n","Epoch: [ 0] [  121/  468] time: 8.9565, train_loss: 0.64363599, train_accuracy: 0.8438, test_Accuracy: 0.8648\n","Epoch: [ 0] [  122/  468] time: 9.0198, train_loss: 0.64734769, train_accuracy: 0.8438, test_Accuracy: 0.8666\n","Epoch: [ 0] [  123/  468] time: 9.0879, train_loss: 0.55819845, train_accuracy: 0.8984, test_Accuracy: 0.8689\n","Epoch: [ 0] [  124/  468] time: 9.1542, train_loss: 0.69756126, train_accuracy: 0.8125, test_Accuracy: 0.8691\n","Epoch: [ 0] [  125/  468] time: 9.2173, train_loss: 0.61413634, train_accuracy: 0.8281, test_Accuracy: 0.8678\n","Epoch: [ 0] [  126/  468] time: 9.2811, train_loss: 0.67818952, train_accuracy: 0.8516, test_Accuracy: 0.8657\n","Epoch: [ 0] [  127/  468] time: 9.3491, train_loss: 0.54028714, train_accuracy: 0.8594, test_Accuracy: 0.8652\n","Epoch: [ 0] [  128/  468] time: 9.4124, train_loss: 0.58314312, train_accuracy: 0.8516, test_Accuracy: 0.8664\n","Epoch: [ 0] [  129/  468] time: 9.4758, train_loss: 0.54268122, train_accuracy: 0.8359, test_Accuracy: 0.8690\n","Epoch: [ 0] [  130/  468] time: 9.5388, train_loss: 0.48266345, train_accuracy: 0.8672, test_Accuracy: 0.8714\n","Epoch: [ 0] [  131/  468] time: 9.6056, train_loss: 0.54862452, train_accuracy: 0.8828, test_Accuracy: 0.8737\n","Epoch: [ 0] [  132/  468] time: 9.6710, train_loss: 0.53038895, train_accuracy: 0.8828, test_Accuracy: 0.8739\n","Epoch: [ 0] [  133/  468] time: 9.7338, train_loss: 0.61599857, train_accuracy: 0.8281, test_Accuracy: 0.8753\n","Epoch: [ 0] [  134/  468] time: 9.8065, train_loss: 0.49099821, train_accuracy: 0.8984, test_Accuracy: 0.8756\n","Epoch: [ 0] [  135/  468] time: 9.8745, train_loss: 0.50002372, train_accuracy: 0.8828, test_Accuracy: 0.8770\n","Epoch: [ 0] [  136/  468] time: 9.9371, train_loss: 0.59565055, train_accuracy: 0.8672, test_Accuracy: 0.8766\n","Epoch: [ 0] [  137/  468] time: 9.9998, train_loss: 0.46828449, train_accuracy: 0.9297, test_Accuracy: 0.8761\n","Epoch: [ 0] [  138/  468] time: 10.0639, train_loss: 0.49817058, train_accuracy: 0.8750, test_Accuracy: 0.8760\n","Epoch: [ 0] [  139/  468] time: 10.1321, train_loss: 0.65023637, train_accuracy: 0.8281, test_Accuracy: 0.8774\n","Epoch: [ 0] [  140/  468] time: 10.1956, train_loss: 0.49933317, train_accuracy: 0.8672, test_Accuracy: 0.8769\n","Epoch: [ 0] [  141/  468] time: 10.2591, train_loss: 0.43562612, train_accuracy: 0.8906, test_Accuracy: 0.8787\n","Epoch: [ 0] [  142/  468] time: 10.3221, train_loss: 0.44270742, train_accuracy: 0.8594, test_Accuracy: 0.8790\n","Epoch: [ 0] [  143/  468] time: 10.3905, train_loss: 0.42276233, train_accuracy: 0.9062, test_Accuracy: 0.8797\n","Epoch: [ 0] [  144/  468] time: 10.4532, train_loss: 0.67600232, train_accuracy: 0.8203, test_Accuracy: 0.8810\n","Epoch: [ 0] [  145/  468] time: 10.5162, train_loss: 0.44794524, train_accuracy: 0.8594, test_Accuracy: 0.8805\n","Epoch: [ 0] [  146/  468] time: 10.5798, train_loss: 0.49286050, train_accuracy: 0.8984, test_Accuracy: 0.8809\n","Epoch: [ 0] [  147/  468] time: 10.6470, train_loss: 0.45784763, train_accuracy: 0.8906, test_Accuracy: 0.8818\n","Epoch: [ 0] [  148/  468] time: 10.7099, train_loss: 0.49416906, train_accuracy: 0.8750, test_Accuracy: 0.8833\n","Epoch: [ 0] [  149/  468] time: 10.7726, train_loss: 0.41557169, train_accuracy: 0.9062, test_Accuracy: 0.8839\n","Epoch: [ 0] [  150/  468] time: 10.8543, train_loss: 0.43360895, train_accuracy: 0.8906, test_Accuracy: 0.8846\n","Epoch: [ 0] [  151/  468] time: 10.9197, train_loss: 0.43822145, train_accuracy: 0.9062, test_Accuracy: 0.8862\n","Epoch: [ 0] [  152/  468] time: 10.9838, train_loss: 0.42577398, train_accuracy: 0.9062, test_Accuracy: 0.8857\n","Epoch: [ 0] [  153/  468] time: 11.0464, train_loss: 0.46238199, train_accuracy: 0.8672, test_Accuracy: 0.8852\n","Epoch: [ 0] [  154/  468] time: 11.1152, train_loss: 0.45799854, train_accuracy: 0.8594, test_Accuracy: 0.8848\n","Epoch: [ 0] [  155/  468] time: 11.1821, train_loss: 0.48426417, train_accuracy: 0.8750, test_Accuracy: 0.8864\n","Epoch: [ 0] [  156/  468] time: 11.2458, train_loss: 0.42584759, train_accuracy: 0.8906, test_Accuracy: 0.8866\n","Epoch: [ 0] [  157/  468] time: 11.3084, train_loss: 0.52781540, train_accuracy: 0.8750, test_Accuracy: 0.8870\n","Epoch: [ 0] [  158/  468] time: 11.3763, train_loss: 0.51879412, train_accuracy: 0.8750, test_Accuracy: 0.8879\n","Epoch: [ 0] [  159/  468] time: 11.4408, train_loss: 0.42216611, train_accuracy: 0.8594, test_Accuracy: 0.8899\n","Epoch: [ 0] [  160/  468] time: 11.5040, train_loss: 0.40407002, train_accuracy: 0.8984, test_Accuracy: 0.8898\n","Epoch: [ 0] [  161/  468] time: 11.5674, train_loss: 0.53209198, train_accuracy: 0.8594, test_Accuracy: 0.8891\n","Epoch: [ 0] [  162/  468] time: 11.6347, train_loss: 0.37548569, train_accuracy: 0.9297, test_Accuracy: 0.8875\n","Epoch: [ 0] [  163/  468] time: 11.6966, train_loss: 0.50474989, train_accuracy: 0.8828, test_Accuracy: 0.8876\n","Epoch: [ 0] [  164/  468] time: 11.7571, train_loss: 0.53797382, train_accuracy: 0.8828, test_Accuracy: 0.8888\n","Epoch: [ 0] [  165/  468] time: 11.8205, train_loss: 0.40928355, train_accuracy: 0.9062, test_Accuracy: 0.8892\n","Epoch: [ 0] [  166/  468] time: 11.8972, train_loss: 0.55779320, train_accuracy: 0.8125, test_Accuracy: 0.8905\n","Epoch: [ 0] [  167/  468] time: 11.9612, train_loss: 0.54519325, train_accuracy: 0.8438, test_Accuracy: 0.8934\n","Epoch: [ 0] [  168/  468] time: 12.0235, train_loss: 0.43127730, train_accuracy: 0.8984, test_Accuracy: 0.8940\n","Epoch: [ 0] [  169/  468] time: 12.0845, train_loss: 0.37493148, train_accuracy: 0.9141, test_Accuracy: 0.8943\n","Epoch: [ 0] [  170/  468] time: 12.1527, train_loss: 0.35993317, train_accuracy: 0.9297, test_Accuracy: 0.8938\n","Epoch: [ 0] [  171/  468] time: 12.2167, train_loss: 0.60080910, train_accuracy: 0.8125, test_Accuracy: 0.8939\n","Epoch: [ 0] [  172/  468] time: 12.2803, train_loss: 0.46236449, train_accuracy: 0.9219, test_Accuracy: 0.8938\n","Epoch: [ 0] [  173/  468] time: 12.3425, train_loss: 0.40949473, train_accuracy: 0.8906, test_Accuracy: 0.8926\n","Epoch: [ 0] [  174/  468] time: 12.4083, train_loss: 0.39386714, train_accuracy: 0.9141, test_Accuracy: 0.8915\n","Epoch: [ 0] [  175/  468] time: 12.4722, train_loss: 0.42051399, train_accuracy: 0.8828, test_Accuracy: 0.8904\n","Epoch: [ 0] [  176/  468] time: 12.5360, train_loss: 0.47778910, train_accuracy: 0.8750, test_Accuracy: 0.8911\n","Epoch: [ 0] [  177/  468] time: 12.5990, train_loss: 0.39048845, train_accuracy: 0.9141, test_Accuracy: 0.8929\n","Epoch: [ 0] [  178/  468] time: 12.6670, train_loss: 0.48708969, train_accuracy: 0.8594, test_Accuracy: 0.8949\n","Epoch: [ 0] [  179/  468] time: 12.7294, train_loss: 0.40915480, train_accuracy: 0.9141, test_Accuracy: 0.8952\n","Epoch: [ 0] [  180/  468] time: 12.7917, train_loss: 0.50007159, train_accuracy: 0.8359, test_Accuracy: 0.8986\n","Epoch: [ 0] [  181/  468] time: 12.8548, train_loss: 0.41843665, train_accuracy: 0.8828, test_Accuracy: 0.8977\n","Epoch: [ 0] [  182/  468] time: 12.9325, train_loss: 0.37483251, train_accuracy: 0.8984, test_Accuracy: 0.8981\n","Epoch: [ 0] [  183/  468] time: 12.9964, train_loss: 0.44014582, train_accuracy: 0.8672, test_Accuracy: 0.8978\n","Epoch: [ 0] [  184/  468] time: 13.0587, train_loss: 0.42783588, train_accuracy: 0.9219, test_Accuracy: 0.8979\n","Epoch: [ 0] [  185/  468] time: 13.1214, train_loss: 0.36024112, train_accuracy: 0.8984, test_Accuracy: 0.8967\n","Epoch: [ 0] [  186/  468] time: 13.1888, train_loss: 0.32571578, train_accuracy: 0.9609, test_Accuracy: 0.8973\n","Epoch: [ 0] [  187/  468] time: 13.2520, train_loss: 0.36936438, train_accuracy: 0.9219, test_Accuracy: 0.8970\n","Epoch: [ 0] [  188/  468] time: 13.3141, train_loss: 0.38667428, train_accuracy: 0.8984, test_Accuracy: 0.8971\n","Epoch: [ 0] [  189/  468] time: 13.3787, train_loss: 0.40383339, train_accuracy: 0.8906, test_Accuracy: 0.8967\n","Epoch: [ 0] [  190/  468] time: 13.4460, train_loss: 0.36828184, train_accuracy: 0.9062, test_Accuracy: 0.8961\n","Epoch: [ 0] [  191/  468] time: 13.5085, train_loss: 0.49912012, train_accuracy: 0.8438, test_Accuracy: 0.8948\n","Epoch: [ 0] [  192/  468] time: 13.5708, train_loss: 0.37428191, train_accuracy: 0.8906, test_Accuracy: 0.8939\n","Epoch: [ 0] [  193/  468] time: 13.6331, train_loss: 0.39651662, train_accuracy: 0.8984, test_Accuracy: 0.8932\n","Epoch: [ 0] [  194/  468] time: 13.6992, train_loss: 0.36607945, train_accuracy: 0.8750, test_Accuracy: 0.8936\n","Epoch: [ 0] [  195/  468] time: 13.7614, train_loss: 0.42753491, train_accuracy: 0.8750, test_Accuracy: 0.8954\n","Epoch: [ 0] [  196/  468] time: 13.8246, train_loss: 0.41848400, train_accuracy: 0.8672, test_Accuracy: 0.8972\n","Epoch: [ 0] [  197/  468] time: 13.8866, train_loss: 0.39031440, train_accuracy: 0.8906, test_Accuracy: 0.8982\n","Epoch: [ 0] [  198/  468] time: 13.9626, train_loss: 0.45412409, train_accuracy: 0.8750, test_Accuracy: 0.9011\n","Epoch: [ 0] [  199/  468] time: 14.0266, train_loss: 0.32182911, train_accuracy: 0.9453, test_Accuracy: 0.9024\n","Epoch: [ 0] [  200/  468] time: 14.0889, train_loss: 0.30880243, train_accuracy: 0.9375, test_Accuracy: 0.8999\n","Epoch: [ 0] [  201/  468] time: 14.1534, train_loss: 0.34425086, train_accuracy: 0.9141, test_Accuracy: 0.8981\n","Epoch: [ 0] [  202/  468] time: 14.2225, train_loss: 0.24750452, train_accuracy: 0.9531, test_Accuracy: 0.8948\n","Epoch: [ 0] [  203/  468] time: 14.2874, train_loss: 0.34645301, train_accuracy: 0.9219, test_Accuracy: 0.8938\n","Epoch: [ 0] [  204/  468] time: 14.3487, train_loss: 0.41551858, train_accuracy: 0.8984, test_Accuracy: 0.8941\n","Epoch: [ 0] [  205/  468] time: 14.4114, train_loss: 0.38451838, train_accuracy: 0.9062, test_Accuracy: 0.8956\n","Epoch: [ 0] [  206/  468] time: 14.4812, train_loss: 0.45542887, train_accuracy: 0.8672, test_Accuracy: 0.9006\n","Epoch: [ 0] [  207/  468] time: 14.5462, train_loss: 0.35477802, train_accuracy: 0.9219, test_Accuracy: 0.9013\n","Epoch: [ 0] [  208/  468] time: 14.6100, train_loss: 0.35882145, train_accuracy: 0.9062, test_Accuracy: 0.9030\n","Epoch: [ 0] [  209/  468] time: 14.6719, train_loss: 0.24663827, train_accuracy: 0.9531, test_Accuracy: 0.9026\n","Epoch: [ 0] [  210/  468] time: 14.7375, train_loss: 0.36553228, train_accuracy: 0.8984, test_Accuracy: 0.9000\n","Epoch: [ 0] [  211/  468] time: 14.7990, train_loss: 0.31416878, train_accuracy: 0.9141, test_Accuracy: 0.8993\n","Epoch: [ 0] [  212/  468] time: 14.8618, train_loss: 0.27439472, train_accuracy: 0.9375, test_Accuracy: 0.8985\n","Epoch: [ 0] [  213/  468] time: 14.9239, train_loss: 0.37102970, train_accuracy: 0.9141, test_Accuracy: 0.8996\n","Epoch: [ 0] [  214/  468] time: 14.9963, train_loss: 0.39698592, train_accuracy: 0.8594, test_Accuracy: 0.9004\n","Epoch: [ 0] [  215/  468] time: 15.0604, train_loss: 0.44627634, train_accuracy: 0.8672, test_Accuracy: 0.9014\n","Epoch: [ 0] [  216/  468] time: 15.1237, train_loss: 0.40608948, train_accuracy: 0.8594, test_Accuracy: 0.9019\n","Epoch: [ 0] [  217/  468] time: 15.1869, train_loss: 0.41253048, train_accuracy: 0.9062, test_Accuracy: 0.9016\n","Epoch: [ 0] [  218/  468] time: 15.2535, train_loss: 0.41970342, train_accuracy: 0.8750, test_Accuracy: 0.9013\n","Epoch: [ 0] [  219/  468] time: 15.3165, train_loss: 0.37610817, train_accuracy: 0.8828, test_Accuracy: 0.9013\n","Epoch: [ 0] [  220/  468] time: 15.3787, train_loss: 0.43028522, train_accuracy: 0.8594, test_Accuracy: 0.9011\n","Epoch: [ 0] [  221/  468] time: 15.4422, train_loss: 0.41187909, train_accuracy: 0.8828, test_Accuracy: 0.9027\n","Epoch: [ 0] [  222/  468] time: 15.5091, train_loss: 0.35831374, train_accuracy: 0.8984, test_Accuracy: 0.9037\n","Epoch: [ 0] [  223/  468] time: 15.5732, train_loss: 0.43614814, train_accuracy: 0.8984, test_Accuracy: 0.9037\n","Epoch: [ 0] [  224/  468] time: 15.6355, train_loss: 0.34375989, train_accuracy: 0.8906, test_Accuracy: 0.9046\n","Epoch: [ 0] [  225/  468] time: 15.6963, train_loss: 0.40219098, train_accuracy: 0.8906, test_Accuracy: 0.9043\n","Epoch: [ 0] [  226/  468] time: 15.7618, train_loss: 0.36680859, train_accuracy: 0.9062, test_Accuracy: 0.9039\n","Epoch: [ 0] [  227/  468] time: 15.8236, train_loss: 0.36261210, train_accuracy: 0.8984, test_Accuracy: 0.9045\n","Epoch: [ 0] [  228/  468] time: 15.8848, train_loss: 0.31258994, train_accuracy: 0.9062, test_Accuracy: 0.9048\n","Epoch: [ 0] [  229/  468] time: 15.9506, train_loss: 0.35393921, train_accuracy: 0.8828, test_Accuracy: 0.9041\n","Epoch: [ 0] [  230/  468] time: 16.0259, train_loss: 0.28750932, train_accuracy: 0.8984, test_Accuracy: 0.9036\n","Epoch: [ 0] [  231/  468] time: 16.0920, train_loss: 0.30431363, train_accuracy: 0.9297, test_Accuracy: 0.9042\n","Epoch: [ 0] [  232/  468] time: 16.1546, train_loss: 0.34591377, train_accuracy: 0.9375, test_Accuracy: 0.9038\n","Epoch: [ 0] [  233/  468] time: 16.2164, train_loss: 0.37008041, train_accuracy: 0.8984, test_Accuracy: 0.9036\n","Epoch: [ 0] [  234/  468] time: 16.2842, train_loss: 0.30077606, train_accuracy: 0.9453, test_Accuracy: 0.9030\n","Epoch: [ 0] [  235/  468] time: 16.3466, train_loss: 0.29904428, train_accuracy: 0.9062, test_Accuracy: 0.9017\n","Epoch: [ 0] [  236/  468] time: 16.4085, train_loss: 0.36749256, train_accuracy: 0.9062, test_Accuracy: 0.9020\n","Epoch: [ 0] [  237/  468] time: 16.4698, train_loss: 0.28133407, train_accuracy: 0.9062, test_Accuracy: 0.9031\n","Epoch: [ 0] [  238/  468] time: 16.5364, train_loss: 0.34575516, train_accuracy: 0.8984, test_Accuracy: 0.9048\n","Epoch: [ 0] [  239/  468] time: 16.6053, train_loss: 0.30664355, train_accuracy: 0.9141, test_Accuracy: 0.9064\n","Epoch: [ 0] [  240/  468] time: 16.6696, train_loss: 0.44096529, train_accuracy: 0.8672, test_Accuracy: 0.9071\n","Epoch: [ 0] [  241/  468] time: 16.7336, train_loss: 0.34263518, train_accuracy: 0.8984, test_Accuracy: 0.9082\n","Epoch: [ 0] [  242/  468] time: 16.8021, train_loss: 0.30082923, train_accuracy: 0.9219, test_Accuracy: 0.9081\n","Epoch: [ 0] [  243/  468] time: 16.8639, train_loss: 0.33024633, train_accuracy: 0.9062, test_Accuracy: 0.9076\n","Epoch: [ 0] [  244/  468] time: 16.9278, train_loss: 0.28431016, train_accuracy: 0.9141, test_Accuracy: 0.9063\n","Epoch: [ 0] [  245/  468] time: 16.9897, train_loss: 0.50488001, train_accuracy: 0.8516, test_Accuracy: 0.9062\n","Epoch: [ 0] [  246/  468] time: 17.0601, train_loss: 0.31806666, train_accuracy: 0.8984, test_Accuracy: 0.9061\n","Epoch: [ 0] [  247/  468] time: 17.1290, train_loss: 0.24078567, train_accuracy: 0.9219, test_Accuracy: 0.9063\n","Epoch: [ 0] [  248/  468] time: 17.2032, train_loss: 0.32073346, train_accuracy: 0.8984, test_Accuracy: 0.9071\n","Epoch: [ 0] [  249/  468] time: 17.2675, train_loss: 0.39071181, train_accuracy: 0.9297, test_Accuracy: 0.9060\n","Epoch: [ 0] [  250/  468] time: 17.3322, train_loss: 0.37793469, train_accuracy: 0.8984, test_Accuracy: 0.9064\n","Epoch: [ 0] [  251/  468] time: 17.3944, train_loss: 0.22349159, train_accuracy: 0.9453, test_Accuracy: 0.9065\n","Epoch: [ 0] [  252/  468] time: 17.4549, train_loss: 0.43021977, train_accuracy: 0.8594, test_Accuracy: 0.9067\n","Epoch: [ 0] [  253/  468] time: 17.5195, train_loss: 0.32063812, train_accuracy: 0.9219, test_Accuracy: 0.9068\n","Epoch: [ 0] [  254/  468] time: 17.5818, train_loss: 0.32039148, train_accuracy: 0.9219, test_Accuracy: 0.9082\n","Epoch: [ 0] [  255/  468] time: 17.6432, train_loss: 0.36047274, train_accuracy: 0.8750, test_Accuracy: 0.9080\n","Epoch: [ 0] [  256/  468] time: 17.7069, train_loss: 0.42498338, train_accuracy: 0.8594, test_Accuracy: 0.9097\n","Epoch: [ 0] [  257/  468] time: 17.7717, train_loss: 0.42145601, train_accuracy: 0.8828, test_Accuracy: 0.9092\n","Epoch: [ 0] [  258/  468] time: 17.8331, train_loss: 0.42463517, train_accuracy: 0.8828, test_Accuracy: 0.9078\n","Epoch: [ 0] [  259/  468] time: 17.8930, train_loss: 0.51697558, train_accuracy: 0.8750, test_Accuracy: 0.9071\n","Epoch: [ 0] [  260/  468] time: 17.9543, train_loss: 0.38915232, train_accuracy: 0.8828, test_Accuracy: 0.9062\n","Epoch: [ 0] [  261/  468] time: 18.0198, train_loss: 0.26058501, train_accuracy: 0.9453, test_Accuracy: 0.9059\n","Epoch: [ 0] [  262/  468] time: 18.0871, train_loss: 0.45835960, train_accuracy: 0.8750, test_Accuracy: 0.9064\n","Epoch: [ 0] [  263/  468] time: 18.1587, train_loss: 0.32953972, train_accuracy: 0.8984, test_Accuracy: 0.9071\n","Epoch: [ 0] [  264/  468] time: 18.2202, train_loss: 0.39386040, train_accuracy: 0.8984, test_Accuracy: 0.9077\n","Epoch: [ 0] [  265/  468] time: 18.2865, train_loss: 0.41050866, train_accuracy: 0.8828, test_Accuracy: 0.9089\n","Epoch: [ 0] [  266/  468] time: 18.3485, train_loss: 0.34287158, train_accuracy: 0.8906, test_Accuracy: 0.9087\n","Epoch: [ 0] [  267/  468] time: 18.4126, train_loss: 0.45639905, train_accuracy: 0.8750, test_Accuracy: 0.9083\n","Epoch: [ 0] [  268/  468] time: 18.4732, train_loss: 0.24640702, train_accuracy: 0.9453, test_Accuracy: 0.9070\n","Epoch: [ 0] [  269/  468] time: 18.5414, train_loss: 0.30227712, train_accuracy: 0.9062, test_Accuracy: 0.9062\n","Epoch: [ 0] [  270/  468] time: 18.6036, train_loss: 0.45285922, train_accuracy: 0.8594, test_Accuracy: 0.9065\n","Epoch: [ 0] [  271/  468] time: 18.6644, train_loss: 0.31250876, train_accuracy: 0.9219, test_Accuracy: 0.9071\n","Epoch: [ 0] [  272/  468] time: 18.7266, train_loss: 0.35481134, train_accuracy: 0.8906, test_Accuracy: 0.9080\n","Epoch: [ 0] [  273/  468] time: 18.7918, train_loss: 0.27200210, train_accuracy: 0.9141, test_Accuracy: 0.9086\n","Epoch: [ 0] [  274/  468] time: 18.8526, train_loss: 0.29281342, train_accuracy: 0.8828, test_Accuracy: 0.9104\n","Epoch: [ 0] [  275/  468] time: 18.9138, train_loss: 0.27116945, train_accuracy: 0.9297, test_Accuracy: 0.9113\n","Epoch: [ 0] [  276/  468] time: 18.9745, train_loss: 0.33870524, train_accuracy: 0.9141, test_Accuracy: 0.9117\n","Epoch: [ 0] [  277/  468] time: 19.0401, train_loss: 0.35234430, train_accuracy: 0.9141, test_Accuracy: 0.9109\n","Epoch: [ 0] [  278/  468] time: 19.1025, train_loss: 0.31556523, train_accuracy: 0.9297, test_Accuracy: 0.9100\n","Epoch: [ 0] [  279/  468] time: 19.1878, train_loss: 0.24031611, train_accuracy: 0.9453, test_Accuracy: 0.9100\n","Epoch: [ 0] [  280/  468] time: 19.2513, train_loss: 0.26284760, train_accuracy: 0.8984, test_Accuracy: 0.9101\n","Epoch: [ 0] [  281/  468] time: 19.3141, train_loss: 0.27424058, train_accuracy: 0.9297, test_Accuracy: 0.9108\n","Epoch: [ 0] [  282/  468] time: 19.3769, train_loss: 0.25151026, train_accuracy: 0.9375, test_Accuracy: 0.9107\n","Epoch: [ 0] [  283/  468] time: 19.4401, train_loss: 0.40402257, train_accuracy: 0.8828, test_Accuracy: 0.9119\n","Epoch: [ 0] [  284/  468] time: 19.5033, train_loss: 0.40580922, train_accuracy: 0.8984, test_Accuracy: 0.9130\n","Epoch: [ 0] [  285/  468] time: 19.5645, train_loss: 0.37888888, train_accuracy: 0.8906, test_Accuracy: 0.9131\n","Epoch: [ 0] [  286/  468] time: 19.6255, train_loss: 0.34135967, train_accuracy: 0.9062, test_Accuracy: 0.9129\n","Epoch: [ 0] [  287/  468] time: 19.6851, train_loss: 0.39550522, train_accuracy: 0.9062, test_Accuracy: 0.9135\n","Epoch: [ 0] [  288/  468] time: 19.7503, train_loss: 0.36115322, train_accuracy: 0.8906, test_Accuracy: 0.9126\n","Epoch: [ 0] [  289/  468] time: 19.8113, train_loss: 0.39007309, train_accuracy: 0.8750, test_Accuracy: 0.9129\n","Epoch: [ 0] [  290/  468] time: 19.8710, train_loss: 0.30597806, train_accuracy: 0.9375, test_Accuracy: 0.9127\n","Epoch: [ 0] [  291/  468] time: 19.9318, train_loss: 0.37151027, train_accuracy: 0.8594, test_Accuracy: 0.9125\n","Epoch: [ 0] [  292/  468] time: 19.9980, train_loss: 0.45847723, train_accuracy: 0.8750, test_Accuracy: 0.9122\n","Epoch: [ 0] [  293/  468] time: 20.0608, train_loss: 0.30309415, train_accuracy: 0.9219, test_Accuracy: 0.9122\n","Epoch: [ 0] [  294/  468] time: 20.1220, train_loss: 0.42015719, train_accuracy: 0.8906, test_Accuracy: 0.9124\n","Epoch: [ 0] [  295/  468] time: 20.1922, train_loss: 0.45017356, train_accuracy: 0.8359, test_Accuracy: 0.9121\n","Epoch: [ 0] [  296/  468] time: 20.2584, train_loss: 0.45301735, train_accuracy: 0.8594, test_Accuracy: 0.9130\n","Epoch: [ 0] [  297/  468] time: 20.3194, train_loss: 0.36458927, train_accuracy: 0.8672, test_Accuracy: 0.9135\n","Epoch: [ 0] [  298/  468] time: 20.3811, train_loss: 0.30434802, train_accuracy: 0.8906, test_Accuracy: 0.9126\n","Epoch: [ 0] [  299/  468] time: 20.4458, train_loss: 0.22722730, train_accuracy: 0.9297, test_Accuracy: 0.9119\n","Epoch: [ 0] [  300/  468] time: 20.5102, train_loss: 0.34526852, train_accuracy: 0.8984, test_Accuracy: 0.9108\n","Epoch: [ 0] [  301/  468] time: 20.5712, train_loss: 0.23588806, train_accuracy: 0.9375, test_Accuracy: 0.9110\n","Epoch: [ 0] [  302/  468] time: 20.6320, train_loss: 0.29009727, train_accuracy: 0.9375, test_Accuracy: 0.9117\n","Epoch: [ 0] [  303/  468] time: 20.6920, train_loss: 0.37146097, train_accuracy: 0.9141, test_Accuracy: 0.9123\n","Epoch: [ 0] [  304/  468] time: 20.7556, train_loss: 0.46686351, train_accuracy: 0.8359, test_Accuracy: 0.9131\n","Epoch: [ 0] [  305/  468] time: 20.8161, train_loss: 0.27610281, train_accuracy: 0.9219, test_Accuracy: 0.9137\n","Epoch: [ 0] [  306/  468] time: 20.8774, train_loss: 0.32635319, train_accuracy: 0.8906, test_Accuracy: 0.9131\n","Epoch: [ 0] [  307/  468] time: 20.9379, train_loss: 0.34565365, train_accuracy: 0.9297, test_Accuracy: 0.9134\n","Epoch: [ 0] [  308/  468] time: 21.0028, train_loss: 0.35568929, train_accuracy: 0.9141, test_Accuracy: 0.9140\n","Epoch: [ 0] [  309/  468] time: 21.0634, train_loss: 0.23618951, train_accuracy: 0.9453, test_Accuracy: 0.9147\n","Epoch: [ 0] [  310/  468] time: 21.1263, train_loss: 0.23933142, train_accuracy: 0.9375, test_Accuracy: 0.9145\n","Epoch: [ 0] [  311/  468] time: 21.1875, train_loss: 0.36935264, train_accuracy: 0.9141, test_Accuracy: 0.9147\n","Epoch: [ 0] [  312/  468] time: 21.2672, train_loss: 0.28341320, train_accuracy: 0.9141, test_Accuracy: 0.9144\n","Epoch: [ 0] [  313/  468] time: 21.3293, train_loss: 0.40634719, train_accuracy: 0.9062, test_Accuracy: 0.9136\n","Epoch: [ 0] [  314/  468] time: 21.3915, train_loss: 0.36621642, train_accuracy: 0.9141, test_Accuracy: 0.9133\n","Epoch: [ 0] [  315/  468] time: 21.4562, train_loss: 0.25698122, train_accuracy: 0.9531, test_Accuracy: 0.9132\n","Epoch: [ 0] [  316/  468] time: 21.5204, train_loss: 0.23567000, train_accuracy: 0.9375, test_Accuracy: 0.9144\n","Epoch: [ 0] [  317/  468] time: 21.5817, train_loss: 0.36539096, train_accuracy: 0.8828, test_Accuracy: 0.9153\n","Epoch: [ 0] [  318/  468] time: 21.6430, train_loss: 0.34371868, train_accuracy: 0.9141, test_Accuracy: 0.9155\n","Epoch: [ 0] [  319/  468] time: 21.7028, train_loss: 0.43098214, train_accuracy: 0.8750, test_Accuracy: 0.9148\n","Epoch: [ 0] [  320/  468] time: 21.7680, train_loss: 0.24917528, train_accuracy: 0.9375, test_Accuracy: 0.9144\n","Epoch: [ 0] [  321/  468] time: 21.8288, train_loss: 0.31016505, train_accuracy: 0.8828, test_Accuracy: 0.9149\n","Epoch: [ 0] [  322/  468] time: 21.8892, train_loss: 0.33009720, train_accuracy: 0.9062, test_Accuracy: 0.9151\n","Epoch: [ 0] [  323/  468] time: 21.9505, train_loss: 0.32031810, train_accuracy: 0.8984, test_Accuracy: 0.9153\n","Epoch: [ 0] [  324/  468] time: 22.0160, train_loss: 0.24896039, train_accuracy: 0.9453, test_Accuracy: 0.9151\n","Epoch: [ 0] [  325/  468] time: 22.0772, train_loss: 0.27469712, train_accuracy: 0.9297, test_Accuracy: 0.9159\n","Epoch: [ 0] [  326/  468] time: 22.1402, train_loss: 0.36421824, train_accuracy: 0.9219, test_Accuracy: 0.9156\n","Epoch: [ 0] [  327/  468] time: 22.2006, train_loss: 0.35242999, train_accuracy: 0.8828, test_Accuracy: 0.9163\n","Epoch: [ 0] [  328/  468] time: 22.2778, train_loss: 0.15267856, train_accuracy: 0.9609, test_Accuracy: 0.9167\n","Epoch: [ 0] [  329/  468] time: 22.3415, train_loss: 0.31132358, train_accuracy: 0.9375, test_Accuracy: 0.9167\n","Epoch: [ 0] [  330/  468] time: 22.4034, train_loss: 0.23397030, train_accuracy: 0.9297, test_Accuracy: 0.9165\n","Epoch: [ 0] [  331/  468] time: 22.4647, train_loss: 0.43593705, train_accuracy: 0.8672, test_Accuracy: 0.9165\n","Epoch: [ 0] [  332/  468] time: 22.5308, train_loss: 0.21531877, train_accuracy: 0.9453, test_Accuracy: 0.9164\n","Epoch: [ 0] [  333/  468] time: 22.5927, train_loss: 0.30487269, train_accuracy: 0.9219, test_Accuracy: 0.9149\n","Epoch: [ 0] [  334/  468] time: 22.6533, train_loss: 0.27304530, train_accuracy: 0.9297, test_Accuracy: 0.9137\n","Epoch: [ 0] [  335/  468] time: 22.7133, train_loss: 0.22511317, train_accuracy: 0.9297, test_Accuracy: 0.9138\n","Epoch: [ 0] [  336/  468] time: 22.7770, train_loss: 0.46998641, train_accuracy: 0.8516, test_Accuracy: 0.9137\n","Epoch: [ 0] [  337/  468] time: 22.8376, train_loss: 0.20092627, train_accuracy: 0.9609, test_Accuracy: 0.9144\n","Epoch: [ 0] [  338/  468] time: 22.8971, train_loss: 0.17529839, train_accuracy: 0.9531, test_Accuracy: 0.9139\n","Epoch: [ 0] [  339/  468] time: 22.9578, train_loss: 0.45723271, train_accuracy: 0.8906, test_Accuracy: 0.9136\n","Epoch: [ 0] [  340/  468] time: 23.0219, train_loss: 0.22141674, train_accuracy: 0.9219, test_Accuracy: 0.9145\n","Epoch: [ 0] [  341/  468] time: 23.0834, train_loss: 0.31737834, train_accuracy: 0.9141, test_Accuracy: 0.9150\n","Epoch: [ 0] [  342/  468] time: 23.1450, train_loss: 0.40674162, train_accuracy: 0.8672, test_Accuracy: 0.9160\n","Epoch: [ 0] [  343/  468] time: 23.2051, train_loss: 0.37967449, train_accuracy: 0.8906, test_Accuracy: 0.9159\n","Epoch: [ 0] [  344/  468] time: 23.2711, train_loss: 0.23647942, train_accuracy: 0.9062, test_Accuracy: 0.9160\n","Epoch: [ 0] [  345/  468] time: 23.3511, train_loss: 0.23037754, train_accuracy: 0.9297, test_Accuracy: 0.9160\n","Epoch: [ 0] [  346/  468] time: 23.4138, train_loss: 0.35013384, train_accuracy: 0.9141, test_Accuracy: 0.9149\n","Epoch: [ 0] [  347/  468] time: 23.4744, train_loss: 0.33029008, train_accuracy: 0.8906, test_Accuracy: 0.9150\n","Epoch: [ 0] [  348/  468] time: 23.5405, train_loss: 0.22891876, train_accuracy: 0.9453, test_Accuracy: 0.9157\n","Epoch: [ 0] [  349/  468] time: 23.6009, train_loss: 0.21545056, train_accuracy: 0.9453, test_Accuracy: 0.9165\n","Epoch: [ 0] [  350/  468] time: 23.6608, train_loss: 0.30581772, train_accuracy: 0.9219, test_Accuracy: 0.9160\n","Epoch: [ 0] [  351/  468] time: 23.7212, train_loss: 0.20297059, train_accuracy: 0.9453, test_Accuracy: 0.9158\n","Epoch: [ 0] [  352/  468] time: 23.7869, train_loss: 0.32074374, train_accuracy: 0.9297, test_Accuracy: 0.9155\n","Epoch: [ 0] [  353/  468] time: 23.8485, train_loss: 0.31900996, train_accuracy: 0.9062, test_Accuracy: 0.9154\n","Epoch: [ 0] [  354/  468] time: 23.9108, train_loss: 0.24631967, train_accuracy: 0.9297, test_Accuracy: 0.9154\n","Epoch: [ 0] [  355/  468] time: 23.9733, train_loss: 0.22197470, train_accuracy: 0.9609, test_Accuracy: 0.9165\n","Epoch: [ 0] [  356/  468] time: 24.0382, train_loss: 0.21880868, train_accuracy: 0.9453, test_Accuracy: 0.9160\n","Epoch: [ 0] [  357/  468] time: 24.0996, train_loss: 0.39438650, train_accuracy: 0.8828, test_Accuracy: 0.9168\n","Epoch: [ 0] [  358/  468] time: 24.1612, train_loss: 0.27627301, train_accuracy: 0.9375, test_Accuracy: 0.9164\n","Epoch: [ 0] [  359/  468] time: 24.2212, train_loss: 0.27983660, train_accuracy: 0.9375, test_Accuracy: 0.9163\n","Epoch: [ 0] [  360/  468] time: 24.2853, train_loss: 0.35534954, train_accuracy: 0.9062, test_Accuracy: 0.9159\n","Epoch: [ 0] [  361/  468] time: 24.3562, train_loss: 0.29182851, train_accuracy: 0.9141, test_Accuracy: 0.9170\n","Epoch: [ 0] [  362/  468] time: 24.4188, train_loss: 0.28174675, train_accuracy: 0.9219, test_Accuracy: 0.9173\n","Epoch: [ 0] [  363/  468] time: 24.4814, train_loss: 0.21987247, train_accuracy: 0.9375, test_Accuracy: 0.9173\n","Epoch: [ 0] [  364/  468] time: 24.5469, train_loss: 0.47961244, train_accuracy: 0.8594, test_Accuracy: 0.9177\n","Epoch: [ 0] [  365/  468] time: 24.6077, train_loss: 0.31588158, train_accuracy: 0.9062, test_Accuracy: 0.9182\n","Epoch: [ 0] [  366/  468] time: 24.6689, train_loss: 0.30239743, train_accuracy: 0.8828, test_Accuracy: 0.9184\n","Epoch: [ 0] [  367/  468] time: 24.7309, train_loss: 0.27732569, train_accuracy: 0.9375, test_Accuracy: 0.9184\n","Epoch: [ 0] [  368/  468] time: 24.7946, train_loss: 0.25443363, train_accuracy: 0.9141, test_Accuracy: 0.9179\n","Epoch: [ 0] [  369/  468] time: 24.8559, train_loss: 0.24069041, train_accuracy: 0.9375, test_Accuracy: 0.9178\n","Epoch: [ 0] [  370/  468] time: 24.9158, train_loss: 0.28675213, train_accuracy: 0.9062, test_Accuracy: 0.9180\n","Epoch: [ 0] [  371/  468] time: 24.9762, train_loss: 0.18660375, train_accuracy: 0.9453, test_Accuracy: 0.9171\n","Epoch: [ 0] [  372/  468] time: 25.0409, train_loss: 0.28826815, train_accuracy: 0.9219, test_Accuracy: 0.9177\n","Epoch: [ 0] [  373/  468] time: 25.1025, train_loss: 0.37176290, train_accuracy: 0.8672, test_Accuracy: 0.9178\n","Epoch: [ 0] [  374/  468] time: 25.1664, train_loss: 0.24224702, train_accuracy: 0.9531, test_Accuracy: 0.9176\n","Epoch: [ 0] [  375/  468] time: 25.2266, train_loss: 0.29537928, train_accuracy: 0.9062, test_Accuracy: 0.9170\n","Epoch: [ 0] [  376/  468] time: 25.2918, train_loss: 0.28748786, train_accuracy: 0.9219, test_Accuracy: 0.9165\n","Epoch: [ 0] [  377/  468] time: 25.3577, train_loss: 0.30856603, train_accuracy: 0.9062, test_Accuracy: 0.9150\n","Epoch: [ 0] [  378/  468] time: 25.4311, train_loss: 0.20594864, train_accuracy: 0.9375, test_Accuracy: 0.9157\n","Epoch: [ 0] [  379/  468] time: 25.4949, train_loss: 0.18865439, train_accuracy: 0.9375, test_Accuracy: 0.9158\n","Epoch: [ 0] [  380/  468] time: 25.5600, train_loss: 0.28458041, train_accuracy: 0.9141, test_Accuracy: 0.9155\n","Epoch: [ 0] [  381/  468] time: 25.6217, train_loss: 0.20941870, train_accuracy: 0.9453, test_Accuracy: 0.9150\n","Epoch: [ 0] [  382/  468] time: 25.6834, train_loss: 0.27872580, train_accuracy: 0.9219, test_Accuracy: 0.9145\n","Epoch: [ 0] [  383/  468] time: 25.7469, train_loss: 0.23731166, train_accuracy: 0.9453, test_Accuracy: 0.9147\n","Epoch: [ 0] [  384/  468] time: 25.8102, train_loss: 0.30617833, train_accuracy: 0.9062, test_Accuracy: 0.9148\n","Epoch: [ 0] [  385/  468] time: 25.8719, train_loss: 0.36334932, train_accuracy: 0.8984, test_Accuracy: 0.9164\n","Epoch: [ 0] [  386/  468] time: 25.9324, train_loss: 0.26894218, train_accuracy: 0.9141, test_Accuracy: 0.9177\n","Epoch: [ 0] [  387/  468] time: 25.9959, train_loss: 0.18236417, train_accuracy: 0.9453, test_Accuracy: 0.9185\n","Epoch: [ 0] [  388/  468] time: 26.0560, train_loss: 0.19329980, train_accuracy: 0.9609, test_Accuracy: 0.9190\n","Epoch: [ 0] [  389/  468] time: 26.1175, train_loss: 0.35789824, train_accuracy: 0.8906, test_Accuracy: 0.9186\n","Epoch: [ 0] [  390/  468] time: 26.1787, train_loss: 0.38738012, train_accuracy: 0.8984, test_Accuracy: 0.9187\n","Epoch: [ 0] [  391/  468] time: 26.2416, train_loss: 0.20059511, train_accuracy: 0.9375, test_Accuracy: 0.9190\n","Epoch: [ 0] [  392/  468] time: 26.3017, train_loss: 0.20989335, train_accuracy: 0.9531, test_Accuracy: 0.9194\n","Epoch: [ 0] [  393/  468] time: 26.3628, train_loss: 0.35268345, train_accuracy: 0.8750, test_Accuracy: 0.9187\n","Epoch: [ 0] [  394/  468] time: 26.4357, train_loss: 0.33410096, train_accuracy: 0.8906, test_Accuracy: 0.9198\n","Epoch: [ 0] [  395/  468] time: 26.5026, train_loss: 0.27002686, train_accuracy: 0.9453, test_Accuracy: 0.9212\n","Epoch: [ 0] [  396/  468] time: 26.5635, train_loss: 0.25605580, train_accuracy: 0.9297, test_Accuracy: 0.9212\n","Epoch: [ 0] [  397/  468] time: 26.6251, train_loss: 0.21541975, train_accuracy: 0.9453, test_Accuracy: 0.9216\n","Epoch: [ 0] [  398/  468] time: 26.6855, train_loss: 0.24780390, train_accuracy: 0.9219, test_Accuracy: 0.9210\n","Epoch: [ 0] [  399/  468] time: 26.7487, train_loss: 0.25512990, train_accuracy: 0.9688, test_Accuracy: 0.9214\n","Epoch: [ 0] [  400/  468] time: 26.8087, train_loss: 0.38173693, train_accuracy: 0.9062, test_Accuracy: 0.9220\n","Epoch: [ 0] [  401/  468] time: 26.8685, train_loss: 0.31079298, train_accuracy: 0.8750, test_Accuracy: 0.9221\n","Epoch: [ 0] [  402/  468] time: 26.9322, train_loss: 0.34581700, train_accuracy: 0.9219, test_Accuracy: 0.9221\n","Epoch: [ 0] [  403/  468] time: 27.0018, train_loss: 0.30473357, train_accuracy: 0.9219, test_Accuracy: 0.9210\n","Epoch: [ 0] [  404/  468] time: 27.0692, train_loss: 0.25600743, train_accuracy: 0.9219, test_Accuracy: 0.9203\n","Epoch: [ 0] [  405/  468] time: 27.1371, train_loss: 0.29895997, train_accuracy: 0.9219, test_Accuracy: 0.9197\n","Epoch: [ 0] [  406/  468] time: 27.2028, train_loss: 0.22538358, train_accuracy: 0.9375, test_Accuracy: 0.9194\n","Epoch: [ 0] [  407/  468] time: 27.2720, train_loss: 0.21689586, train_accuracy: 0.9375, test_Accuracy: 0.9199\n","Epoch: [ 0] [  408/  468] time: 27.3372, train_loss: 0.15914527, train_accuracy: 0.9531, test_Accuracy: 0.9199\n","Epoch: [ 0] [  409/  468] time: 27.4038, train_loss: 0.28902611, train_accuracy: 0.8984, test_Accuracy: 0.9209\n","Epoch: [ 0] [  410/  468] time: 27.4850, train_loss: 0.36338669, train_accuracy: 0.8594, test_Accuracy: 0.9217\n","Epoch: [ 0] [  411/  468] time: 27.5819, train_loss: 0.23146309, train_accuracy: 0.9375, test_Accuracy: 0.9231\n","Epoch: [ 0] [  412/  468] time: 27.6499, train_loss: 0.22449023, train_accuracy: 0.9375, test_Accuracy: 0.9233\n","Epoch: [ 0] [  413/  468] time: 27.7184, train_loss: 0.31494975, train_accuracy: 0.9062, test_Accuracy: 0.9224\n","Epoch: [ 0] [  414/  468] time: 27.7894, train_loss: 0.25224534, train_accuracy: 0.9297, test_Accuracy: 0.9221\n","Epoch: [ 0] [  415/  468] time: 27.8546, train_loss: 0.28143686, train_accuracy: 0.9141, test_Accuracy: 0.9212\n","Epoch: [ 0] [  416/  468] time: 27.9200, train_loss: 0.16757801, train_accuracy: 0.9453, test_Accuracy: 0.9208\n","Epoch: [ 0] [  417/  468] time: 27.9896, train_loss: 0.25911850, train_accuracy: 0.9297, test_Accuracy: 0.9215\n","Epoch: [ 0] [  418/  468] time: 28.0553, train_loss: 0.35868686, train_accuracy: 0.8984, test_Accuracy: 0.9210\n","Epoch: [ 0] [  419/  468] time: 28.1226, train_loss: 0.18362370, train_accuracy: 0.9531, test_Accuracy: 0.9215\n","Epoch: [ 0] [  420/  468] time: 28.1893, train_loss: 0.23917294, train_accuracy: 0.9688, test_Accuracy: 0.9207\n","Epoch: [ 0] [  421/  468] time: 28.2586, train_loss: 0.29666424, train_accuracy: 0.9141, test_Accuracy: 0.9207\n","Epoch: [ 0] [  422/  468] time: 28.3245, train_loss: 0.26553309, train_accuracy: 0.9062, test_Accuracy: 0.9205\n","Epoch: [ 0] [  423/  468] time: 28.3891, train_loss: 0.19939306, train_accuracy: 0.9375, test_Accuracy: 0.9219\n","Epoch: [ 0] [  424/  468] time: 28.4574, train_loss: 0.22370298, train_accuracy: 0.9141, test_Accuracy: 0.9226\n","Epoch: [ 0] [  425/  468] time: 28.5437, train_loss: 0.29094467, train_accuracy: 0.9141, test_Accuracy: 0.9227\n","Epoch: [ 0] [  426/  468] time: 28.6114, train_loss: 0.31272125, train_accuracy: 0.9062, test_Accuracy: 0.9226\n","Epoch: [ 0] [  427/  468] time: 28.6771, train_loss: 0.31058338, train_accuracy: 0.9297, test_Accuracy: 0.9228\n","Epoch: [ 0] [  428/  468] time: 28.7435, train_loss: 0.27379686, train_accuracy: 0.9219, test_Accuracy: 0.9228\n","Epoch: [ 0] [  429/  468] time: 28.8128, train_loss: 0.24578542, train_accuracy: 0.9219, test_Accuracy: 0.9236\n","Epoch: [ 0] [  430/  468] time: 28.8792, train_loss: 0.30234769, train_accuracy: 0.9141, test_Accuracy: 0.9236\n","Epoch: [ 0] [  431/  468] time: 28.9446, train_loss: 0.21038300, train_accuracy: 0.9453, test_Accuracy: 0.9246\n","Epoch: [ 0] [  432/  468] time: 29.0099, train_loss: 0.26358595, train_accuracy: 0.9141, test_Accuracy: 0.9246\n","Epoch: [ 0] [  433/  468] time: 29.0801, train_loss: 0.32050040, train_accuracy: 0.8828, test_Accuracy: 0.9252\n","Epoch: [ 0] [  434/  468] time: 29.1483, train_loss: 0.25890201, train_accuracy: 0.9531, test_Accuracy: 0.9247\n","Epoch: [ 0] [  435/  468] time: 29.2130, train_loss: 0.30313694, train_accuracy: 0.9062, test_Accuracy: 0.9230\n","Epoch: [ 0] [  436/  468] time: 29.2785, train_loss: 0.29939386, train_accuracy: 0.9141, test_Accuracy: 0.9213\n","Epoch: [ 0] [  437/  468] time: 29.3500, train_loss: 0.34345821, train_accuracy: 0.8672, test_Accuracy: 0.9211\n","Epoch: [ 0] [  438/  468] time: 29.4161, train_loss: 0.22967903, train_accuracy: 0.9219, test_Accuracy: 0.9207\n","Epoch: [ 0] [  439/  468] time: 29.4852, train_loss: 0.38545528, train_accuracy: 0.9062, test_Accuracy: 0.9216\n","Epoch: [ 0] [  440/  468] time: 29.5666, train_loss: 0.26953703, train_accuracy: 0.9219, test_Accuracy: 0.9223\n","Epoch: [ 0] [  441/  468] time: 29.6354, train_loss: 0.21530703, train_accuracy: 0.9297, test_Accuracy: 0.9227\n","Epoch: [ 0] [  442/  468] time: 29.7012, train_loss: 0.22915643, train_accuracy: 0.9375, test_Accuracy: 0.9237\n","Epoch: [ 0] [  443/  468] time: 29.7666, train_loss: 0.18965065, train_accuracy: 0.9531, test_Accuracy: 0.9243\n","Epoch: [ 0] [  444/  468] time: 29.8387, train_loss: 0.28669375, train_accuracy: 0.9062, test_Accuracy: 0.9240\n","Epoch: [ 0] [  445/  468] time: 29.9045, train_loss: 0.18814367, train_accuracy: 0.9531, test_Accuracy: 0.9231\n","Epoch: [ 0] [  446/  468] time: 29.9702, train_loss: 0.32008392, train_accuracy: 0.9062, test_Accuracy: 0.9218\n","Epoch: [ 0] [  447/  468] time: 30.0353, train_loss: 0.28192094, train_accuracy: 0.9297, test_Accuracy: 0.9223\n","Epoch: [ 0] [  448/  468] time: 30.1063, train_loss: 0.25407612, train_accuracy: 0.9141, test_Accuracy: 0.9218\n","Epoch: [ 0] [  449/  468] time: 30.1727, train_loss: 0.32160965, train_accuracy: 0.9219, test_Accuracy: 0.9222\n","Epoch: [ 0] [  450/  468] time: 30.2403, train_loss: 0.27849019, train_accuracy: 0.9062, test_Accuracy: 0.9226\n","Epoch: [ 0] [  451/  468] time: 30.3063, train_loss: 0.30926031, train_accuracy: 0.8906, test_Accuracy: 0.9237\n","Epoch: [ 0] [  452/  468] time: 30.3770, train_loss: 0.28564125, train_accuracy: 0.9297, test_Accuracy: 0.9247\n","Epoch: [ 0] [  453/  468] time: 30.4440, train_loss: 0.22334811, train_accuracy: 0.9297, test_Accuracy: 0.9237\n","Epoch: [ 0] [  454/  468] time: 30.5108, train_loss: 0.24684069, train_accuracy: 0.9453, test_Accuracy: 0.9229\n","Epoch: [ 0] [  455/  468] time: 30.5916, train_loss: 0.27300221, train_accuracy: 0.9141, test_Accuracy: 0.9214\n","Epoch: [ 0] [  456/  468] time: 30.6716, train_loss: 0.35757095, train_accuracy: 0.8359, test_Accuracy: 0.9194\n","Epoch: [ 0] [  457/  468] time: 30.7426, train_loss: 0.32039946, train_accuracy: 0.8906, test_Accuracy: 0.9192\n","Epoch: [ 0] [  458/  468] time: 30.8147, train_loss: 0.15529163, train_accuracy: 0.9609, test_Accuracy: 0.9207\n","Epoch: [ 0] [  459/  468] time: 30.8861, train_loss: 0.21029636, train_accuracy: 0.9219, test_Accuracy: 0.9211\n","Epoch: [ 0] [  460/  468] time: 30.9561, train_loss: 0.31123012, train_accuracy: 0.8984, test_Accuracy: 0.9221\n","Epoch: [ 0] [  461/  468] time: 31.0271, train_loss: 0.25438559, train_accuracy: 0.9297, test_Accuracy: 0.9224\n","Epoch: [ 0] [  462/  468] time: 31.0983, train_loss: 0.42177969, train_accuracy: 0.8906, test_Accuracy: 0.9231\n","Epoch: [ 0] [  463/  468] time: 31.1695, train_loss: 0.28693235, train_accuracy: 0.9297, test_Accuracy: 0.9239\n","Epoch: [ 0] [  464/  468] time: 31.2468, train_loss: 0.29671538, train_accuracy: 0.9297, test_Accuracy: 0.9247\n","Epoch: [ 0] [  465/  468] time: 31.3194, train_loss: 0.25506675, train_accuracy: 0.9141, test_Accuracy: 0.9249\n","Epoch: [ 0] [  466/  468] time: 31.3930, train_loss: 0.22911315, train_accuracy: 0.9297, test_Accuracy: 0.9256\n","Epoch: [ 0] [  467/  468] time: 31.4705, train_loss: 0.21983993, train_accuracy: 0.9688, test_Accuracy: 0.9254\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3_xZYkmqGXo6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}