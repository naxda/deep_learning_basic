{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5_2_logistic_classification_diabetes.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vUEYc6wKa-Ra","colab_type":"code","outputId":"3e0f0ebb-4bd0-4e47-aab6-f4534ddc0f0f","executionInfo":{"status":"ok","timestamp":1557927802974,"user_tz":-540,"elapsed":17882,"user":{"displayName":"SoonYoung Jung","photoUrl":"","userId":"08526165032976493552"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["#logistic classification을 diabetes data를 활용해서 모델을 만들어보자\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","print(tf.__version__)\n","tf.enable_eager_execution()\n","\n","# data\n","xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n","x_train = xy[:, 0:-1]\n","y_train = xy[:, [-1]]\n","\n","print('xy:\\n{}'.format(xy))\n","print('x_train:\\n{}'.format(x_train))\n","# print('y_train:\\n{}'.format(y_train))\n","print(x_train.shape, y_train.shape)\n","\n","# hyper parameter\n","# batch_size = x_train.shape[0]\n","batch_size = len(x_train)\n","n_epoch = 1000\n","learning_rate = 0.1\n","\n","# initialize dataset, W, b\n","dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))\n","W = tf.Variable(tf.random_normal([8, 1]), name='weight')\n","b = tf.Variable(tf.random_normal([1]), name='bias')\n","\n","# hypothesis는 Wx+b를 sigmoid를 activation으로 취한것을 사용\n","def logistic_regression(features):\n","  hypothesis = tf.keras.activations.sigmoid(tf.matmul(features, W)+b)\n","  return hypothesis\n","\n","# 손실함수로는 crossentropy를 사용한다\n","def loss_fn(features, labels):\n","  hypothesis = logistic_regression(features)\n","  loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(labels, hypothesis))\n","  return loss\n","\n","# 손실 값의 gradient를 계산한다.\n","def grad(features, labels):\n","  hypothesis = logistic_regression(features)\n","  with tf.GradientTape() as tape:\n","    loss_value = loss_fn(features, labels)\n","  return tape.gradient(loss_value, [W, b])\n","\n","# gradientdescent시 움직일 보폭을 결정\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n","\n","# 1000번의 epoch동안 gradient를 변화시켜 가며 손실이 최소가 되는 점을 찾는다\n","EPOCHS = 1001\n","for step in range(EPOCHS):\n","  total_loss = 0.\n","  for features, labels in dataset:\n","    grads = grad(features, labels)# 손실 값의 gradient를 계산\n","    optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\n","    loss = loss_fn(features, labels)\n","    total_loss += loss\n","    if step % 100 == 0:\n","      print('Epoch {0}: {1:.8f}'.format(step, total_loss))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["1.13.1\n","xy:\n","[[-0.294118   0.487437   0.180328  ... -0.53117   -0.0333333  0.       ]\n"," [-0.882353  -0.145729   0.0819672 ... -0.766866  -0.666667   1.       ]\n"," [-0.0588235  0.839196   0.0491803 ... -0.492741  -0.633333   0.       ]\n"," ...\n"," [-0.411765   0.21608    0.180328  ... -0.857387  -0.7        1.       ]\n"," [-0.882353   0.266332  -0.0163934 ... -0.768574  -0.133333   0.       ]\n"," [-0.882353  -0.0653266  0.147541  ... -0.797609  -0.933333   1.       ]]\n","x_train:\n","[[-0.294118    0.487437    0.180328   ...  0.00149028 -0.53117\n","  -0.0333333 ]\n"," [-0.882353   -0.145729    0.0819672  ... -0.207153   -0.766866\n","  -0.666667  ]\n"," [-0.0588235   0.839196    0.0491803  ... -0.305514   -0.492741\n","  -0.633333  ]\n"," ...\n"," [-0.411765    0.21608     0.180328   ... -0.219076   -0.857387\n","  -0.7       ]\n"," [-0.882353    0.266332   -0.0163934  ... -0.102832   -0.768574\n","  -0.133333  ]\n"," [-0.882353   -0.0653266   0.147541   ... -0.0938897  -0.797609\n","  -0.933333  ]]\n","(759, 8) (759, 1)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","Epoch 0: 1.12687528\n","Epoch 100: 0.83052200\n","Epoch 200: 0.70486075\n","Epoch 300: 0.65330863\n","Epoch 400: 0.62953693\n","Epoch 500: 0.61618841\n","Epoch 600: 0.60699904\n","Epoch 700: 0.59964925\n","Epoch 800: 0.59324521\n","Epoch 900: 0.58742577\n","Epoch 1000: 0.58203483\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OgqGrMzjeRi9","colab_type":"code","colab":{}},"source":[" "],"execution_count":0,"outputs":[]}]}